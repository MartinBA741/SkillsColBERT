{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make documentembeddings using SkillsColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install pytorch-pretrained-bert pytorch-nlp keras scikit-learn matplotlib tensorflow\n",
    "\n",
    "#https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lede musikalsk personale</td>\n",
       "      <td>Tildele og forvalte personaleopgaver på område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>føre tilsyn med fængselsprocedurer</td>\n",
       "      <td>Føre tilsyn med driften af et fængsel eller an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anvende antioppressiv praksis</td>\n",
       "      <td>Identificere undertrykkelse i samfund, økonomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kontrollere overensstemmelse med jernbaneforsk...</td>\n",
       "      <td>Inspicere rullende materiel, komponenter og sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identificere tilgængelige tjenester</td>\n",
       "      <td>Identificere de forskellige tjenester, der er ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                           lede musikalsk personale   \n",
       "1                 føre tilsyn med fængselsprocedurer   \n",
       "2                      anvende antioppressiv praksis   \n",
       "3  kontrollere overensstemmelse med jernbaneforsk...   \n",
       "4                identificere tilgængelige tjenester   \n",
       "\n",
       "                                           documents  \n",
       "0  Tildele og forvalte personaleopgaver på område...  \n",
       "1  Føre tilsyn med driften af et fængsel eller an...  \n",
       "2  Identificere undertrykkelse i samfund, økonomi...  \n",
       "3  Inspicere rullende materiel, komponenter og sy...  \n",
       "4  Identificere de forskellige tjenester, der er ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\data\\skills_description.csv', sep='\\t', encoding='utf-8')\n",
    "df = df.rename(columns={'preferredLabel':'query', 'description': 'documents'})\n",
    "df = df[['query', 'documents']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Be patient...\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(f' running on {device} with {n_gpu} number of GPUs. Name of GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of document:\n",
      " [CLS] Tildele og forvalte personaleopgaver på områder såsom instrumentering, bearbejdning, reproduktion af musik og stemmetræning. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add special ColBERT tokens to documents\n",
    "documents =  [\"[CLS] \" + query + \" [SEP]\" for query in df['documents']]\n",
    "print(\"\\nExample of document:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize the first document: \n",
      " ['[CLS]', 'tildele', 'og', 'forvalt', '##e', 'personale', '##opgaver', 'pa', 'om', '##rad', '##er', 'sas', '##om', 'instrumenter', '##ing', ',', 'bearbejdning', ',', 'reproduktion', 'af', 'musik', 'og', 'stemme', '##træning', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "model_path = r'J:\\VOA\\MABI\\Deep Learning\\my_DTU_project\\Models\\danish_bert_uncased_v2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in documents]\n",
    "\n",
    "print (f'\\nTokenize the first document: \\n {tokenized_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids.shape: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum document length. \n",
    "MAX_LEN_DOC = 128\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_docs]\n",
    "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN_DOC, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of input_ids.shape: {d_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of d_attention_masks: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks for documents\n",
    "d_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in d_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  d_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of d_attention_masks: {np.shape(d_attention_masks)}')\n",
    "\n",
    "assert d_input_ids.shape == np.shape(d_attention_masks), 'dimensions of document d_input_ids and d_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model\n",
    "Queries and documents have now been tokenized to the vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "\n",
    "config = BertConfig.from_pretrained(model_path + r'\\bert_config.json')\n",
    "bert_base = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SkillsColBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "          super(SkillsColBERT, self).__init__()\n",
    "          self.bert = bert_base \n",
    "          ### New layers:\n",
    "          #TODO: \n",
    "          # self.finalLinear = nn.Linear(768, 32) # 32 is \"low\" for faster computation of MaxSim (it is independent of sequence lentgh)\n",
    "          \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "          sequence_output, pooled_output = self.bert(ids, attention_mask=mask) # sequence_output shape is: (batch_size, sequence_length, 768)\n",
    "               \n",
    "          # We apply the linear layer in line with ColBERT paper. The linear layer (which applies a linear transformation)\n",
    "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
    "          # a single token in the input sequence) and outputs 32 numbers for every token\n",
    "          # so the logits are of shape (batch_size, sequence_length, 32)\n",
    "          \n",
    "          #TODO: \n",
    "          # sequence_output = self.finalLinear(sequence_output)\n",
    "          sequence_output = F.softmax(sequence_output, dim=1)\n",
    "\n",
    "          return sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.path.isdir(f'data/doc_embeddings/tensor_{str(1)}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 of size 100 out of 134.85\n",
      "batch 1 of size 100 out of 134.85\n",
      "batch 2 of size 100 out of 134.85\n",
      "batch 3 of size 100 out of 134.85\n",
      "batch 4 of size 100 out of 134.85\n",
      "batch 5 of size 100 out of 134.85\n",
      "batch 6 of size 100 out of 134.85\n",
      "batch 7 of size 100 out of 134.85\n",
      "batch 8 of size 100 out of 134.85\n",
      "batch 9 of size 100 out of 134.85\n",
      "batch 10 of size 100 out of 134.85\n",
      "batch 11 of size 100 out of 134.85\n",
      "batch 12 of size 100 out of 134.85\n",
      "batch 13 of size 100 out of 134.85\n",
      "batch 14 of size 100 out of 134.85\n",
      "batch 15 of size 100 out of 134.85\n",
      "batch 16 of size 100 out of 134.85\n",
      "batch 17 of size 100 out of 134.85\n",
      "batch 18 of size 100 out of 134.85\n",
      "batch 19 of size 100 out of 134.85\n",
      "batch 20 of size 100 out of 134.85\n",
      "batch 21 of size 100 out of 134.85\n",
      "batch 22 of size 100 out of 134.85\n",
      "batch 23 of size 100 out of 134.85\n",
      "batch 24 of size 100 out of 134.85\n",
      "batch 25 of size 100 out of 134.85\n",
      "batch 26 of size 100 out of 134.85\n",
      "batch 27 of size 100 out of 134.85\n",
      "batch 28 of size 100 out of 134.85\n",
      "batch 29 of size 100 out of 134.85\n",
      "batch 30 of size 100 out of 134.85\n",
      "batch 31 of size 100 out of 134.85\n",
      "batch 32 of size 100 out of 134.85\n",
      "batch 33 of size 100 out of 134.85\n",
      "batch 34 of size 100 out of 134.85\n",
      "batch 35 of size 100 out of 134.85\n",
      "batch 36 of size 100 out of 134.85\n",
      "batch 37 of size 100 out of 134.85\n",
      "batch 38 of size 100 out of 134.85\n",
      "batch 39 of size 100 out of 134.85\n",
      "batch 40 of size 100 out of 134.85\n",
      "batch 41 of size 100 out of 134.85\n",
      "batch 42 of size 100 out of 134.85\n",
      "batch 43 of size 100 out of 134.85\n",
      "batch 44 of size 100 out of 134.85\n",
      "batch 45 of size 100 out of 134.85\n",
      "batch 46 of size 100 out of 134.85\n",
      "batch 47 of size 100 out of 134.85\n",
      "batch 48 of size 100 out of 134.85\n",
      "batch 49 of size 100 out of 134.85\n",
      "batch 50 of size 100 out of 134.85\n",
      "batch 51 of size 100 out of 134.85\n",
      "batch 52 of size 100 out of 134.85\n",
      "batch 53 of size 100 out of 134.85\n",
      "batch 54 of size 100 out of 134.85\n",
      "batch 55 of size 100 out of 134.85\n",
      "batch 56 of size 100 out of 134.85\n",
      "batch 57 of size 100 out of 134.85\n",
      "batch 58 of size 100 out of 134.85\n",
      "batch 59 of size 100 out of 134.85\n",
      "batch 60 of size 100 out of 134.85\n",
      "batch 61 of size 100 out of 134.85\n",
      "batch 62 of size 100 out of 134.85\n",
      "batch 63 of size 100 out of 134.85\n",
      "batch 64 of size 100 out of 134.85\n",
      "batch 65 of size 100 out of 134.85\n",
      "batch 66 of size 100 out of 134.85\n",
      "batch 67 of size 100 out of 134.85\n",
      "batch 68 of size 100 out of 134.85\n",
      "batch 69 of size 100 out of 134.85\n",
      "batch 70 of size 100 out of 134.85\n",
      "batch 71 of size 100 out of 134.85\n",
      "batch 72 of size 100 out of 134.85\n",
      "batch 73 of size 100 out of 134.85\n",
      "batch 74 of size 100 out of 134.85\n",
      "batch 75 of size 100 out of 134.85\n",
      "batch 76 of size 100 out of 134.85\n",
      "batch 77 of size 100 out of 134.85\n",
      "batch 78 of size 100 out of 134.85\n",
      "batch 79 of size 100 out of 134.85\n",
      "batch 80 of size 100 out of 134.85\n",
      "batch 81 of size 100 out of 134.85\n",
      "batch 82 of size 100 out of 134.85\n",
      "batch 83 of size 100 out of 134.85\n",
      "batch 84 of size 100 out of 134.85\n",
      "batch 85 of size 100 out of 134.85\n",
      "batch 86 of size 100 out of 134.85\n",
      "batch 87 of size 100 out of 134.85\n",
      "batch 88 of size 100 out of 134.85\n",
      "batch 89 of size 100 out of 134.85\n",
      "batch 90 of size 100 out of 134.85\n",
      "batch 91 of size 100 out of 134.85\n",
      "batch 92 of size 100 out of 134.85\n",
      "batch 93 of size 100 out of 134.85\n",
      "batch 94 of size 100 out of 134.85\n",
      "batch 95 of size 100 out of 134.85\n",
      "batch 96 of size 100 out of 134.85\n",
      "batch 97 of size 100 out of 134.85\n",
      "batch 98 of size 100 out of 134.85\n",
      "batch 99 of size 100 out of 134.85\n",
      "batch 100 of size 100 out of 134.85\n",
      "batch 101 of size 100 out of 134.85\n",
      "batch 102 of size 100 out of 134.85\n",
      "batch 103 of size 100 out of 134.85\n",
      "batch 104 of size 100 out of 134.85\n",
      "batch 105 of size 100 out of 134.85\n",
      "batch 106 of size 100 out of 134.85\n",
      "batch 107 of size 100 out of 134.85\n",
      "batch 108 of size 100 out of 134.85\n",
      "batch 109 of size 100 out of 134.85\n",
      "batch 110 of size 100 out of 134.85\n",
      "batch 111 of size 100 out of 134.85\n",
      "batch 112 of size 100 out of 134.85\n",
      "batch 113 of size 100 out of 134.85\n",
      "batch 114 of size 100 out of 134.85\n",
      "batch 115 of size 100 out of 134.85\n",
      "batch 116 of size 100 out of 134.85\n",
      "batch 117 of size 100 out of 134.85\n",
      "batch 118 of size 100 out of 134.85\n",
      "batch 119 of size 100 out of 134.85\n",
      "batch 120 of size 100 out of 134.85\n",
      "batch 121 of size 100 out of 134.85\n",
      "batch 122 of size 100 out of 134.85\n",
      "batch 123 of size 100 out of 134.85\n",
      "batch 124 of size 100 out of 134.85\n",
      "batch 125 of size 100 out of 134.85\n",
      "batch 126 of size 100 out of 134.85\n",
      "batch 127 of size 100 out of 134.85\n",
      "batch 128 of size 100 out of 134.85\n",
      "batch 129 of size 100 out of 134.85\n",
      "batch 130 of size 100 out of 134.85\n",
      "batch 131 of size 100 out of 134.85\n",
      "batch 132 of size 100 out of 134.85\n",
      "batch 133 of size 100 out of 134.85\n",
      "batch 134 of size 100 out of 134.85\n",
      "total time taken this loop:  8673.039563417435\n"
     ]
    }
   ],
   "source": [
    "# Choose batch_size\n",
    "stide_len = 100\n",
    "\n",
    "my_model  = SkillsColBERT()\n",
    "my_model.to(torch.device(device))\n",
    "\n",
    "\n",
    "# Initialize tensor to store output\n",
    "d_id    = torch.tensor(d_input_ids[:stide_len]).to(torch.device(device)).to(torch.int64)\n",
    "d_mask  = torch.tensor(d_attention_masks[:stide_len]).to(torch.device(device)).to(torch.int64)\n",
    "doc_output = my_model(d_id, mask=d_mask)\n",
    "\n",
    "step = 0\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "while step < len(df):\n",
    "    if os.path.exists(os.path.join(os.getcwd(), 'doc_embeddings', f'tensor_{i}.pt')):\n",
    "        step += stide_len\n",
    "        i += 1\n",
    "    else:\n",
    "        if step % (500)==0:\n",
    "            print(f'batch {i} of size {stide_len} out of {len(df)/stide_len}')\n",
    "\n",
    "        d_id    = torch.tensor(d_input_ids[step:step+stide_len]).to(torch.device(device)).to(torch.int64)\n",
    "        d_mask  = torch.tensor(np.array(d_attention_masks[step:step+stide_len])).to(torch.device(device)).to(torch.int64)\n",
    "\n",
    "        # Find Embeddings of documents and save to disk\n",
    "        torch.save(my_model(d_id, mask=d_mask), f'./doc_embeddings/tensor_{i}.pt')\n",
    "\n",
    "        # Add stride_length to step\n",
    "        step += stide_len\n",
    "        i += 1\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"total time taken this loop: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading document embedding 101\n",
      "loading document embedding 102\n",
      "loading document embedding 103\n",
      "loading document embedding 104\n",
      "loading document embedding 105\n",
      "loading document embedding 106\n",
      "loading document embedding 107\n",
      "loading document embedding 108\n",
      "loading document embedding 109\n",
      "loading document embedding 110\n",
      "loading document embedding 111\n",
      "loading document embedding 112\n",
      "loading document embedding 113\n",
      "loading document embedding 114\n",
      "loading document embedding 115\n",
      "loading document embedding 116\n",
      "loading document embedding 117\n",
      "loading document embedding 118\n",
      "loading document embedding 119\n",
      "loading document embedding 120\n",
      "loading document embedding 121\n",
      "loading document embedding 122\n",
      "loading document embedding 123\n",
      "loading document embedding 124\n",
      "loading document embedding 125\n",
      "loading document embedding 126\n",
      "loading document embedding 127\n",
      "loading document embedding 128\n",
      "loading document embedding 129\n",
      "loading document embedding 130\n",
      "loading document embedding 131\n",
      "loading document embedding 132\n",
      "loading document embedding 133\n",
      "loading document embedding 134\n"
     ]
    }
   ],
   "source": [
    "load_doc_embeddings = torch.load(f'./doc_embeddings/tensor_{0}.pt')\n",
    "\n",
    "i = 1\n",
    "while if os.path.exists(os.path.join(os.getcwd(), 'doc_embeddings', f'tensor_{i}.pt')):\n",
    "    print(f'loading document embedding {i}')\n",
    "    load_doc_embeddings = torch.cat((load_doc_embeddings, torch.load(f'./doc_embeddings/tensor_{i}.pt')), 0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10400, 128, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_doc_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62490302a320790e9096d978396a0f6884d50306ab9199b7a47371992da1d123"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('colbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

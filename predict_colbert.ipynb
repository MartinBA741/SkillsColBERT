{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate SkillsColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install pytorch-pretrained-bert pytorch-nlp keras scikit-learn matplotlib tensorflow\n",
    "\n",
    "#https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "    a) Dimensions of max function in MaxSim method function.\n",
    "        - max of column vectors in matrix OR max of row vectors in columns --> 24 dimensional\n",
    "    b) Training of my ColBERT model\n",
    "        - [Q] and [D] in vocabulary --> Drop\n",
    "        - Weights in additional linear layer of 32\n",
    "        - [MASK] as padding instead of [PAD]\n",
    "    c) How to save:\n",
    "        The model (in github) --> Drop\n",
    "        The document embeddings\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lede musikalsk personale</td>\n",
       "      <td>Tildele og forvalte personaleopgaver på område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>føre tilsyn med fængselsprocedurer</td>\n",
       "      <td>Føre tilsyn med driften af et fængsel eller an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anvende antioppressiv praksis</td>\n",
       "      <td>Identificere undertrykkelse i samfund, økonomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kontrollere overensstemmelse med jernbaneforsk...</td>\n",
       "      <td>Inspicere rullende materiel, komponenter og sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identificere tilgængelige tjenester</td>\n",
       "      <td>Identificere de forskellige tjenester, der er ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                           lede musikalsk personale   \n",
       "1                 føre tilsyn med fængselsprocedurer   \n",
       "2                      anvende antioppressiv praksis   \n",
       "3  kontrollere overensstemmelse med jernbaneforsk...   \n",
       "4                identificere tilgængelige tjenester   \n",
       "\n",
       "                                           documents  \n",
       "0  Tildele og forvalte personaleopgaver på område...  \n",
       "1  Føre tilsyn med driften af et fængsel eller an...  \n",
       "2  Identificere undertrykkelse i samfund, økonomi...  \n",
       "3  Inspicere rullende materiel, komponenter og sy...  \n",
       "4  Identificere de forskellige tjenester, der er ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\data\\skills_description.csv', sep='\\t', encoding='utf-8')\n",
    "df = df.rename(columns={'preferredLabel':'query', 'description': 'documents'})\n",
    "df = df[['query', 'documents']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Be patient...\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device==\"cuda\":\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)\n",
    "    print(f'Running on {device} with {n_gpu} number of GPUs')\n",
    "else:\n",
    "    print(f'Running on {device}. Be patient...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of query:\n",
      " [CLS] lede musikalsk personale [SEP]\n",
      "\n",
      "Example of document:\n",
      " [CLS] Tildele og forvalte personaleopgaver på områder såsom instrumentering, bearbejdning, reproduktion af musik og stemmetræning. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add special ColBERT tokens to queries and documents\n",
    "queries = [\"[CLS] \" + query + \" [SEP]\" for query in df['query']]\n",
    "\n",
    "documents =  [\"[CLS] \" + query + \" [SEP]\" for query in df['documents']]\n",
    "\n",
    "print(\"Example of query:\\n\", queries[0])\n",
    "print(\"\\nExample of document:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence: \n",
      " ['[CLS]', 'lede', 'musikalsk', 'personale', '[SEP]']\n",
      "\n",
      "Tokenize the first document: \n",
      " ['[CLS]', 'tildele', 'og', 'forvalt', '##e', 'personale', '##opgaver', 'pa', 'om', '##rad', '##er', 'sas', '##om', 'instrumenter', '##ing', ',', 'bearbejdning', ',', 'reproduktion', 'af', 'musik', 'og', 'stemme', '##træning', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "model_path = r'J:\\VOA\\MABI\\Deep Learning\\my_DTU_project\\Models\\danish_bert_uncased_v2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "\n",
    "#tokenize queries\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in queries]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in documents]\n",
    "\n",
    "print(f'Tokenize the first sentence: \\n {tokenized_texts[0]}')\n",
    "print (f'\\nTokenize the first document: \\n {tokenized_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of sequences\n",
    "len_queries = [len(x) for x in tokenized_texts]\n",
    "len_documents = [len(x) for x in tokenized_docs]\n",
    "\n",
    "# Plot length of queries and documents\n",
    "n_bins = 20\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(len_queries, bins=n_bins)\n",
    "axs[0].set_title('Queries length',fontsize=12)\n",
    "axs[1].hist(len_documents, bins=n_bins)\n",
    "axs[1].set_title('Document length',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eye-balling the plot we determine to set maximum sequence length of queries to 24 and documents to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query ids:\n",
      " q_input_ids.shape = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum query length. \n",
    "MAX_LEN_Q = 24\n",
    "\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "q_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "q_input_ids = pad_sequences(q_input_ids, maxlen=MAX_LEN_Q, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of query ids:\\n q_input_ids.shape = {q_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query attention mask:\n",
      " q_attention_masks = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create query attention masks\n",
    "q_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in q_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  q_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of query attention mask:\\n q_attention_masks = {np.shape(q_attention_masks)}')\n",
    "\n",
    "assert q_input_ids.shape == np.shape(q_attention_masks), 'dimensions of q_input_ids and q_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids.shape: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum document length. \n",
    "MAX_LEN_DOC = 128\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_docs]\n",
    "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN_DOC, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of input_ids.shape: {d_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of d_attention_masks: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks for documents\n",
    "d_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in d_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  d_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of d_attention_masks: {np.shape(d_attention_masks)}')\n",
    "\n",
    "assert d_input_ids.shape == np.shape(d_attention_masks), 'dimensions of document d_input_ids and d_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model\n",
    "Queries and documents have now been tokenized to the vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "\n",
    "config = BertConfig.from_pretrained(model_path + r'\\bert_config.json')\n",
    "bert_base = BertModel(config)\n",
    "\n",
    "#param_optimizer = list(bert_base.named_parameters())\n",
    "#print(bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SkillsColBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "          super(SkillsColBERT, self).__init__()\n",
    "          self.bert = bert_base \n",
    "          ### New layers:\n",
    "          #TODO: \n",
    "          # self.finalLinear = nn.Linear(768, 32) # 32 is \"low\" for faster computation of MaxSim (it is independent of sequence lentgh)\n",
    "          \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "          sequence_output, pooled_output = self.bert(ids, attention_mask=mask) # sequence_output shape is: (batch_size, sequence_length, 768)\n",
    "               \n",
    "          # We apply the linear layer in line with ColBERT paper. The linear layer (which applies a linear transformation)\n",
    "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
    "          # a single token in the input sequence) and outputs 32 numbers for every token\n",
    "          # so the logits are of shape (batch_size, sequence_length, 32)\n",
    "          \n",
    "          #TODO: \n",
    "          # sequence_output = self.finalLinear(sequence_output)\n",
    "          sequence_output = F.softmax(sequence_output, dim=1)\n",
    "\n",
    "          return sequence_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Skills ColBERT model to embed the first X query and document pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try model on first X query and document pairs\n",
    "sample_size = 30\n",
    "\n",
    "#np.random.seed(seed=741)\n",
    "#samples = np.random.randint(0,len(df),sample_size)\n",
    "\n",
    "q_id    = torch.tensor(q_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "q_mask  = torch.tensor(np.array(q_attention_masks[:sample_size])).to(torch.device(device)).to(torch.int64)\n",
    "\n",
    "d_id    = torch.tensor(d_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "d_mask  = torch.tensor(np.array(d_attention_masks[:sample_size])).to(torch.device(device)).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding size:     torch.Size([30, 24, 768])\n",
      "Document embedding size:  torch.Size([30, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "#bert_base.to(torch.device(device))\n",
    "my_model  = SkillsColBERT()\n",
    "my_model.to(torch.device(device))\n",
    "\n",
    "# Embeddings of queries\n",
    "q_outputs = my_model(q_id, mask=q_mask)\n",
    "\n",
    "# Embeddings of documents\n",
    "d_outputs = my_model(d_id, mask=d_mask)\n",
    "\n",
    "#With bert_base shape is: torch.Size([batch_size, 24, 768]) and torch.Size([batch_size, 128, 768])\n",
    "print('Query embedding size:    ', q_outputs.shape) \n",
    "print('Document embedding size: ', d_outputs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, given a query sequence $q = q_0 q_1...q_l$ and a document sequence $d = d_0 d_1...d_n$, we compute the bags of embeddings $E_q$ and $E_d$ in the following manner:\n",
    "\n",
    "* $E_q$ := Normalize( CNN( BERT(“[Q]$q_0 q_1...q_l$ ##...#”) ) )\n",
    "\n",
    "* $E_d$ := Normalize( CNN( BERT(“[D]$d_0 d_1...d_l$ ...d_n”) ) )\n",
    "\n",
    "where '#' refers to the [mask] tokens. In my implementation of ColBERT the output dimensions are as follow:\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_d) = [ 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_D) = [13.485 \\times 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The relevancy score, MaxSim, is defined as follows:\n",
    "\n",
    "$$ S_{q,d} = \\sum_{i \\in ||E_q||} \\max_{j \\in ||E_d||} E_{q_i} * E_{d_j}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxSim(q, D):\n",
    "    '''Takes in the embeddings of a query, q, and all documents' embeddings, D.\n",
    "        Return a tensor of the query's similarity scores to all documents in D.'''\n",
    "\n",
    "    # repeat q for faster matrix multiplication (faster than loop)\n",
    "    batch_size=D.shape[0]\n",
    "    q_X = q.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    # multiply the same query q against all documents (in D)\n",
    "    batch_mm = torch.bmm(q_X, D.permute(0,2,1))\n",
    "    \n",
    "    maks, _ = torch.max(batch_mm, dim=2) # dim=1 or dim=2\n",
    "    #print(maks.shape) # should be (batch_size, 24)\n",
    "    \n",
    "    # Sum over maximum values --> return vector of length len(D)\n",
    "    S_qD = torch.sum(maks, dim=1)\n",
    "    \n",
    "    return S_qD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exampleof implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 33.68it/s]\n"
     ]
    }
   ],
   "source": [
    "most_similar_doc_score = []\n",
    "most_similar_docID = []\n",
    "\n",
    " # Define D as all documents:\n",
    "D = d_outputs\n",
    "\n",
    "for q_no in tqdm(range(sample_size)):\n",
    "    \n",
    "    # Select one query\n",
    "    q = q_outputs[q_no]\n",
    "\n",
    "    # Compute similarity scores for all \n",
    "    S_qD = MaxSim(q, D)\n",
    "    maks, maks_id = torch.max(S_qD, dim=0)\n",
    "\n",
    "    most_similar_doc_score.append(float(maks))\n",
    "    most_similar_docID.append(int(maks_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAANPUlEQVR4nO3df4xl5V3H8fdHto1CiYVwReSHg01LUolKM2q1tdKfWUsjNWkaNtKAYtYYqdQ0VloT6T8mpGKtiaZmbVcw4jYNpS2xUUtqK5ogOou0/Fhamrqli8AOIbGtJiLy9Y+5tMNld+7de8/O8J2+XwmZc55z5p7vsw98OPvc8yNVhSSpn+/a6gIkSfMxwCWpKQNckpoywCWpKQNckprasZkHO+2002ppaWkzDylJ7e3fv/+xqhpNtm9qgC8tLbGysrKZh5Sk9pJ89UjtTqFIUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlObeiemJG2Gpas/9a3lg9detIWVHF+egUtSUwa4JDVlgEtSUwa4JDVlgEtSUwa4JDVlgEtSUwa4JDU1NcCT7E1yOMk9E+1vT3J/knuTvO/4lShJOpJZzsCvB3aub0jyauBi4Eer6oeB64YvTZK0kakBXlW3AY9PNP8acG1V/c94n8PHoTZJ0gbmnQN/CfAzSe5I8g9JfvxoOybZnWQlycrq6uqch5MkTZo3wHcApwIvB34L+GiSHGnHqtpTVctVtTwajeY8nCRp0rwBfgi4udb8C/AUcNpwZUmSppk3wD8BvBogyUuA5wOPDVSTJGkGU58HnmQfcCFwWpJDwDXAXmDv+NLCJ4DLqqqOZ6GSpGeaGuBVtesomy4duBZJ0jHwTkxJasoAl6SmDHBJasoAl6SmDHBJasoAl6SmDHBJasoAl6SmDHBJasoAl6SmDHBJasoAl6SmDHBJasoAl6SmDHBJampqgCfZm+Tw+OUNk9vemaSS+Do1Sdpks5yBXw/snGxMcjbwBuDBgWuSJM1gaoBX1W3A40fY9IfAuwBfpSZJW2CuOfAkFwMPVdXnZ9h3d5KVJCurq6vzHE6SdATHHOBJTgTeA/zuLPtX1Z6qWq6q5dFodKyHkyQdxTxn4C8CzgU+n+QgcBZwZ5LvH7IwSdLGpr6VflJV3Q1839Pr4xBfrqrHBqxLkjTFLJcR7gNuB85LcijJFce/LEnSNFPPwKtq15TtS4NVI0mamXdiSlJTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTs7zQYW+Sw0nuWdf2+0nuT/KFJB9P8sLjWqUk6VlmOQO/Htg50XYrcH5V/QjwJeDdA9clSZpiaoBX1W3A4xNtn66qJ8er/8zai40lSZtoiDnwXwb+ZoDPkSQdg4UCPMnvAE8CN26wz+4kK0lWVldXFzmcJGmduQM8yeXAm4BfrKo62n5VtaeqlqtqeTQazXs4SdKEqW+lP5IkO4F3AT9bVf89bEmSpFnMchnhPuB24Lwkh5JcAfwxcDJwa5K7kvzpca5TkjRh6hl4Ve06QvOHj0MtkqRj4J2YktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTc3yRp69SQ4nuWdd26lJbk3ywPjnKce3TEnSpFnOwK8Hdk60XQ18pqpeDHxmvC5J2kRTA7yqbgMen2i+GLhhvHwD8OZhy5IkTTPvHPjpVfXwePkR4PSj7Zhkd5KVJCurq6tzHk6SNGnhLzGrqoDaYPueqlququXRaLTo4SRJY/MG+KNJzgAY/zw8XEmSpFnMG+C3AJeNly8DPjlMOZKkWc1yGeE+4HbgvCSHklwBXAu8PskDwOvG65KkTbRj2g5Vtesom147cC2SpGPgnZiS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNGeCS1NRCAZ7kN5Pcm+SeJPuSfPdQhUmSNjZ3gCc5E/gNYLmqzgdOAC4ZqjBJ0sYWnULZAXxPkh3AicB/LF6SJGkWcwd4VT0EXAc8CDwM/GdVfXpyvyS7k6wkWVldXZ2/UknSMywyhXIKcDFwLvADwElJLp3cr6r2VNVyVS2PRqP5K5UkPcMiUyivA/69qlar6n+Bm4GfHqYsSdI0iwT4g8DLk5yYJKy9pf7AMGVJkqZZZA78DuAm4E7g7vFn7RmoLknSFDsW+eWquga4ZqBaJEnHwDsxJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmjLAJakpA1ySmloowJO8MMlNSe5PciDJTw1VmCRpYwu9kQf4I+Bvq+otSZ4PnDhATZKkGcwd4Em+F3gVcDlAVT0BPDFMWZKkaRaZQjkXWAX+PMm/JflQkpMmd0qyO8lKkpXV1dUFDidJWm+RAN8BvAz4YFVdAPwXcPXkTlW1p6qWq2p5NBotcDhJ0nqLBPgh4FBV3TFev4m1QJckbYK5A7yqHgG+luS8cdNrgfsGqUqSNNWiV6G8HbhxfAXKV4BfWrwkSdIsFgrwqroLWB6mFEnSsfBOTElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqauEAT3LC+KXGfz1EQZKk2QxxBn4VcGCAz5EkHYOFAjzJWcBFwIeGKUeSNKtF34n5AeBdwMlH2yHJbmA3wDnnnLPg4SSph6WrP/WM9YPXXjT4MeY+A0/yJuBwVe3faL+q2lNVy1W1PBqN5j2cJGnCIlMorwB+PslB4CPAa5L85SBVSZKmmjvAq+rdVXVWVS0BlwB/X1WXDlaZJGlDXgcuSU0t+iUmAFX1OeBzQ3yWJGk2noFLUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlMGuCQ1NchlhN9J1j/f4Hg820BbzzFWF56BS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNbXIOzHPTvLZJPcluTfJVUMWJkna2CJ3Yj4JvLOq7kxyMrA/ya1Vdd9AtUmSNrDIOzEfrqo7x8vfAA4AZw5VmCRpY4PMgSdZAi4A7jjCtt1JVpKsrK6uDnE4SRIDBHiSFwAfA95RVV+f3F5Ve6pquaqWR6PRooeTJI0tFOBJnsdaeN9YVTcPU5IkaRaLXIUS4MPAgap6/3AlSZJmscgZ+CuAtwGvSXLX+J83DlSXJGmKuS8jrKp/AjJgLZKkY+CdmJLUlAEuSU0Z4JLUlAEuSU0Z4JLUlAEuSU0Z4JLU1CKPk91US1d/6lvLB6+9aAsrkZ7Nfz83j3/W3+YZuCQ1ZYBLUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlMGuCQ1ZYBLUlOLvhNzZ5IvJvlykquHKkqSNN0i78Q8AfgT4OeAlwK7krx0qMIkSRtb5Az8J4AvV9VXquoJ4CPAxcOUJUmaJlU13y8mbwF2VtWvjNffBvxkVV05sd9uYPd49Tzgi3PWehrw2Jy/28V276P962+79/G52r8frKrRZONxf5hVVe0B9iz6OUlWqmp5gJKes7Z7H+1ff9u9j936t8gUykPA2evWzxq3SZI2wSIB/q/Ai5Ocm+T5wCXALcOUJUmaZu4plKp6MsmVwN8BJwB7q+rewSp7toWnYRrY7n20f/1t9z626t/cX2JKkraWd2JKUlMGuCQ11SLAt/st+0kOJrk7yV1JVra6niEk2ZvkcJJ71rWdmuTWJA+Mf56ylTUu4ij9e2+Sh8bjeFeSN25ljYtIcnaSzya5L8m9Sa4at2+LMdygf63G8Dk/Bz6+Zf9LwOuBQ6xd/bKrqu7b0sIGlOQgsFxVz8UbCOaS5FXAN4G/qKrzx23vAx6vqmvH/yM+pap+eyvrnNdR+vde4JtVdd1W1jaEJGcAZ1TVnUlOBvYDbwYuZxuM4Qb9eyuNxrDDGbi37DdUVbcBj080XwzcMF6+gbX/YFo6Sv+2jap6uKruHC9/AzgAnMk2GcMN+tdKhwA/E/jauvVDNPyDnqKATyfZP370wHZ1elU9PF5+BDh9K4s5Tq5M8oXxFEvL6YVJSZaAC4A72IZjONE/aDSGHQL8O8Erq+plrD3Z8dfHfz3f1mpt7u65PX937D4IvAj4MeBh4A+2tJoBJHkB8DHgHVX19fXbtsMYHqF/rcawQ4Bv+1v2q+qh8c/DwMdZmzbajh4dzz0+PQd5eIvrGVRVPVpV/1dVTwF/RvNxTPI81sLtxqq6edy8bcbwSP3rNoYdAnxb37Kf5KTxlygkOQl4A3DPxr/V1i3AZePly4BPbmEtg3s62MZ+gcbjmCTAh4EDVfX+dZu2xRgerX/dxvA5fxUKwPhSng/w7Vv2f29rKxpOkh9i7awb1h5t8FfboX9J9gEXsvZ4zkeBa4BPAB8FzgG+Cry1qlp+EXiU/l3I2l+9CzgI/Oq6+eJWkrwS+EfgbuCpcfN7WJsnbj+GG/RvF43GsEWAS5KercMUiiTpCAxwSWrKAJekpgxwSWrKAJekpgxwSWrKAJekpv4fgsuDKznTggsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "plt.hist(most_similar_docID, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "q_IDs = [x for x in range(sample_size)]\n",
    "plt.scatter(q_IDs, most_similar_docID)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_1score:  0.0037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = q_IDs\n",
    "y_pred = most_similar_docID\n",
    "\n",
    "print('f_1score: ', round(f1_score(y_true, y_pred, average='macro'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rights: 1 out of 30 \n",
      " 0.033% accuracy\n"
     ]
    }
   ],
   "source": [
    "rights = sum(np.array(y_true) == np.array(y_pred))\n",
    "wrongs = sum(np.array(y_true) != np.array(y_pred))\n",
    "\n",
    "print(f'rights: {rights} out of {rights+wrongs} \\n {np.round(rights/(rights+wrongs),3)}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>udnytte avancerede kliniske kompetencer</td>\n",
       "      <td>Anvende avancerede kliniske kompetencer i best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      query  \\\n",
       "24  udnytte avancerede kliniske kompetencer   \n",
       "\n",
       "                                            documents  \n",
       "24  Anvende avancerede kliniske kompetencer i best...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct = df.iloc[:sample_size,:].loc[(np.array(y_true) == np.array(y_pred))]\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overvåge og vedligeholde boringsvæskerne eller \"mudder\". Tilføje forskellige kemikalier til væsken med henblik på at udføre forskellige funktioner i brøndoperationer: holde borebitten afkølet, hydrostatisk tryk, osv.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect specific document. - Why are 49 and 79 getting this many hits. \n",
    "df.documents[79]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "BERCH embedding Euclidean distance"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62490302a320790e9096d978396a0f6884d50306ab9199b7a47371992da1d123"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('colbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

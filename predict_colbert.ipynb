{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate SkillsColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install pytorch-pretrained-bert pytorch-nlp keras scikit-learn matplotlib tensorflow\n",
    "\n",
    "#https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lede musikalsk personale</td>\n",
       "      <td>Tildele og forvalte personaleopgaver på område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>føre tilsyn med fængselsprocedurer</td>\n",
       "      <td>Føre tilsyn med driften af et fængsel eller an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anvende antioppressiv praksis</td>\n",
       "      <td>Identificere undertrykkelse i samfund, økonomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kontrollere overensstemmelse med jernbaneforsk...</td>\n",
       "      <td>Inspicere rullende materiel, komponenter og sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identificere tilgængelige tjenester</td>\n",
       "      <td>Identificere de forskellige tjenester, der er ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                           lede musikalsk personale   \n",
       "1                 føre tilsyn med fængselsprocedurer   \n",
       "2                      anvende antioppressiv praksis   \n",
       "3  kontrollere overensstemmelse med jernbaneforsk...   \n",
       "4                identificere tilgængelige tjenester   \n",
       "\n",
       "                                           documents  \n",
       "0  Tildele og forvalte personaleopgaver på område...  \n",
       "1  Føre tilsyn med driften af et fængsel eller an...  \n",
       "2  Identificere undertrykkelse i samfund, økonomi...  \n",
       "3  Inspicere rullende materiel, komponenter og sy...  \n",
       "4  Identificere de forskellige tjenester, der er ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\data\\skills_description.csv', sep='\\t', encoding='utf-8')\n",
    "df = df.rename(columns={'preferredLabel':'query', 'description': 'documents'})\n",
    "df = df[['query', 'documents']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Be patient...\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device==\"cuda\":\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)\n",
    "    print(f'Running on {device} with {n_gpu} number of GPUs')\n",
    "else:\n",
    "    print(f'Running on {device}. Be patient...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of query:\n",
      " [CLS] [Q] lede musikalsk personale [SEP]\n",
      "\n",
      "Example of document:\n",
      " [CLS] [D] Tildele og forvalte personaleopgaver på områder såsom instrumentering, bearbejdning, reproduktion af musik og stemmetræning. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add special ColBERT tokens to queries and documents\n",
    "queries = [\"[CLS] [Q] \" + query + \" [SEP]\" for query in df['query']]\n",
    "\n",
    "documents =  [\"[CLS] [D] \" + query + \" [SEP]\" for query in df['documents']]\n",
    "\n",
    "print(\"Example of query:\\n\", queries[0])\n",
    "print(\"\\nExample of document:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence: \n",
      " ['[CLS]', '[UNK]', 'q', '[UNK]', 'lede', 'musikalsk', 'personale', '[SEP]']\n",
      "\n",
      "Tokenize the first document: \n",
      " ['[CLS]', '[UNK]', 'd', '[UNK]', 'tildele', 'og', 'forvalt', '##e', 'personale', '##opgaver', 'pa', 'om', '##rad', '##er', 'sas', '##om', 'instrumenter', '##ing', ',', 'bearbejdning', ',', 'reproduktion', 'af', 'musik', 'og', 'stemme', '##træning', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "model_path = r'J:\\VOA\\MABI\\Deep Learning\\my_DTU_project\\Models\\danish_bert_uncased_v2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "\n",
    "#tokenize queries\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in queries]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in documents]\n",
    "\n",
    "print(f'Tokenize the first sentence: \\n {tokenized_texts[0]}')\n",
    "print (f'\\nTokenize the first document: \\n {tokenized_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of sequences\n",
    "len_queries = [len(x) for x in tokenized_texts]\n",
    "len_documents = [len(x) for x in tokenized_docs]\n",
    "\n",
    "# Plot length of queries and documents\n",
    "n_bins = 20\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(len_queries, bins=n_bins)\n",
    "axs[0].set_title('Queries length',fontsize=12)\n",
    "axs[1].hist(len_documents, bins=n_bins)\n",
    "axs[1].set_title('Document length',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eye-balling the plot we determine to set maximum sequence length of queries to 24 and documents to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query ids:\n",
      " q_input_ids.shape = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum query length. \n",
    "MAX_LEN_Q = 24\n",
    "\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "q_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "q_input_ids = pad_sequences(q_input_ids, maxlen=MAX_LEN_Q, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of query ids:\\n q_input_ids.shape = {q_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query attention mask:\n",
      " q_attention_masks = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create query attention masks\n",
    "q_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in q_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  q_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of query attention mask:\\n q_attention_masks = {np.shape(q_attention_masks)}')\n",
    "\n",
    "assert q_input_ids.shape == np.shape(q_attention_masks), 'dimensions of q_input_ids and q_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids.shape: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum document length. \n",
    "MAX_LEN_DOC = 128\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_docs]\n",
    "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN_DOC, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of input_ids.shape: {d_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of d_attention_masks: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks for documents\n",
    "d_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in d_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  d_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of d_attention_masks: {np.shape(d_attention_masks)}')\n",
    "\n",
    "assert d_input_ids.shape == np.shape(d_attention_masks), 'dimensions of document d_input_ids and d_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model\n",
    "Queries and documents have now been tokenized to the vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "\n",
    "config = BertConfig.from_pretrained(model_path + r'\\bert_config.json')\n",
    "bert_base = BertModel(config)\n",
    "\n",
    "#param_optimizer = list(bert_base.named_parameters())\n",
    "#print(bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.bert = bert_base \n",
    "          ### New layers:\n",
    "          self.linear1 = nn.Linear(768, 32) # 32 is \"low\" for faster computation of MaxSim (it is independent of sequence lentgh)\n",
    "          \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "          sequence_output, pooled_output = self.bert(ids, attention_mask=mask) # sequence_output shape is: (batch_size, sequence_length, 768)\n",
    "               \n",
    "          # We apply the linear layer in line with ColBERT paper. The linear layer (which applies a linear transformation)\n",
    "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
    "          # a single token in the input sequence) and outputs 32 numbers for every token\n",
    "          # so the logits are of shape (batch_size, sequence_length, 32)\n",
    "          sequence_output = self.linear1(sequence_output)\n",
    "          sequence_output = F.softmax(sequence_output, dim=1)\n",
    "\n",
    "          #linear2_output = self.linear2(linear2_output)\n",
    "\n",
    "          return sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try model on first 10 query and document pairs\n",
    "sample_size = 100\n",
    "q_id    = torch.tensor(q_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "q_mask  = torch.tensor(q_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "\n",
    "d_id    = torch.tensor(d_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "d_mask  = torch.tensor(d_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 24, 32])\n",
      "torch.Size([100, 128, 32])\n"
     ]
    }
   ],
   "source": [
    "#bert_base.to(torch.device(device))\n",
    "my_model  = CustomBERTModel()\n",
    "my_model.to(torch.device(device))\n",
    "\n",
    "# Embeddings of queries\n",
    "q_outputs = my_model(q_id, mask=q_mask)\n",
    "\n",
    "# Embeddings of documents\n",
    "d_outputs = my_model(d_id, mask=d_mask)\n",
    "\n",
    "#With bert_base shape is: torch.Size([batch_size, 24, 768]) and torch.Size([batch_size, 128, 768])\n",
    "print('Query embedding size:    ', q_outputs.shape) \n",
    "print('Document embedding size: ', d_outputs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_mm shape:  torch.Size([100, 24, 128])\n",
      "maks_qd.shape:   torch.Size([100, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "# Now batch multiply, i.e. tensor multiplication or rather matrix mulætiply for each batch\n",
    "batch_mm = torch.bmm(q_outputs, d_outputs.permute(0,2,1))\n",
    "print('batch_mm shape: ', batch_mm.shape)\n",
    "\n",
    "# Find maximum value in q*d^T for each query token in each batch\n",
    "maks_qd, maks_inds = torch.max(batch_mm, dim=2)\n",
    "print('maks_qd.shape:  ', maks_qd.shape)\n",
    "\n",
    "\n",
    "sum_qd = torch.sum(maks_qd, dim=1)\n",
    "sum_qd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, given a query sequence $q = q_0 q_1...q_l$ and a document sequence $d = d_0 d_1...d_n$, we compute the bags of embeddings $E_q$ and $E_d$ in the following manner:\n",
    "\n",
    "* $E_q$ := Normalize( CNN( BERT(“[Q]$q_0 q_1...q_l$ ##...#”) ) )\n",
    "\n",
    "* $E_d$ := Normalize( CNN( BERT(“[D]$d_0 d_1...d_l$ ...d_n”) ) )\n",
    "\n",
    "where '#' refers to the [mask] tokens. In my implementation of ColBERT the output dimensions are as follow:\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_d) = [ 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    dim(E_Q) = [batch_{size} \\times 24 \\times 32] \\\\\n",
    "    dim(E_D) = [batch_{size} \\times 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The relevancy score, MaxSim, is defined as follows:\n",
    "\n",
    "$$ S_{q,d} = \\sum_{i \\in ||E_q||} \\max_{j \\in ||E_d||} E_{q_i} * E_{d_j}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MaxSim(q, D):\n",
    "    '''Takes in a query, q, and return it's similarity score to\n",
    "        all documents in  D.'''\n",
    "\n",
    "    # repeat q for faster matrix multiplication (faster than loop)\n",
    "    batch_size=D.shape[0]\n",
    "    q_X = q.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    # multiply the same query q against all documents (in D)\n",
    "    batch_mm = torch.bmm(q_X, D.permute(0,2,1))\n",
    "    \n",
    "    maks, _ = torch.max(batch_mm, dim=1) # dim=1 or dim=2\n",
    "    \n",
    "    # Sum over maximum values --> return vector of length len(D)\n",
    "    S_qD = torch.sum(maks, dim=1)\n",
    "    \n",
    "    return S_qD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 181.28it/s]\n"
     ]
    }
   ],
   "source": [
    "most_similar_doc_score = []\n",
    "most_similar_docID = []\n",
    "\n",
    "D = d_outputs\n",
    "\n",
    "for q_no in tqdm.tqdm(range(100)):\n",
    "    \n",
    "    # Select one query and all documents:\n",
    "    q = q_outputs[q_no]\n",
    "\n",
    "    S_qD = MaxSim(q, D)\n",
    "    maks, maks_id = torch.max(S_qD, dim=0)\n",
    "\n",
    "    most_similar_doc_score.append(float(maks))\n",
    "    most_similar_docID.append(int(maks_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "plt.hist(most_similar_docID, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_id = "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62490302a320790e9096d978396a0f6884d50306ab9199b7a47371992da1d123"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('colbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate SkillsColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install pytorch-pretrained-bert pytorch-nlp keras scikit-learn matplotlib tensorflow\n",
    "\n",
    "#https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lede musikalsk personale</td>\n",
       "      <td>Tildele og forvalte personaleopgaver på område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>føre tilsyn med fængselsprocedurer</td>\n",
       "      <td>Føre tilsyn med driften af et fængsel eller an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anvende antioppressiv praksis</td>\n",
       "      <td>Identificere undertrykkelse i samfund, økonomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kontrollere overensstemmelse med jernbaneforsk...</td>\n",
       "      <td>Inspicere rullende materiel, komponenter og sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identificere tilgængelige tjenester</td>\n",
       "      <td>Identificere de forskellige tjenester, der er ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                           lede musikalsk personale   \n",
       "1                 føre tilsyn med fængselsprocedurer   \n",
       "2                      anvende antioppressiv praksis   \n",
       "3  kontrollere overensstemmelse med jernbaneforsk...   \n",
       "4                identificere tilgængelige tjenester   \n",
       "\n",
       "                                           documents  \n",
       "0  Tildele og forvalte personaleopgaver på område...  \n",
       "1  Føre tilsyn med driften af et fængsel eller an...  \n",
       "2  Identificere undertrykkelse i samfund, økonomi...  \n",
       "3  Inspicere rullende materiel, komponenter og sy...  \n",
       "4  Identificere de forskellige tjenester, der er ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\data\\skills_description.csv', sep='\\t', encoding='utf-8')\n",
    "df = df.rename(columns={'preferredLabel':'query', 'description': 'documents'})\n",
    "df = df[['query', 'documents']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Be patient...\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device==\"cuda\":\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)\n",
    "    print(f'Running on {device} with {n_gpu} number of GPUs')\n",
    "else:\n",
    "    print(f'Running on {device}. Be patient...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of query:\n",
      " [CLS] [Q] lede musikalsk personale [SEP]\n",
      "\n",
      "Example of document:\n",
      " [CLS] [D] Tildele og forvalte personaleopgaver på områder såsom instrumentering, bearbejdning, reproduktion af musik og stemmetræning. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add special ColBERT tokens to queries and documents\n",
    "queries = [\"[CLS] [Q] \" + query + \" [SEP]\" for query in df['query']]\n",
    "\n",
    "documents =  [\"[CLS] [D] \" + query + \" [SEP]\" for query in df['documents']]\n",
    "\n",
    "print(\"Example of query:\\n\", queries[0])\n",
    "print(\"\\nExample of document:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence: \n",
      " ['[CLS]', '[UNK]', 'q', '[UNK]', 'lede', 'musikalsk', 'personale', '[SEP]']\n",
      "\n",
      "Tokenize the first document: \n",
      " ['[CLS]', '[UNK]', 'd', '[UNK]', 'tildele', 'og', 'forvalt', '##e', 'personale', '##opgaver', 'pa', 'om', '##rad', '##er', 'sas', '##om', 'instrumenter', '##ing', ',', 'bearbejdning', ',', 'reproduktion', 'af', 'musik', 'og', 'stemme', '##træning', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "model_path = r'J:\\VOA\\MABI\\Deep Learning\\my_DTU_project\\Models\\danish_bert_uncased_v2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "\n",
    "#tokenize queries\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in queries]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in documents]\n",
    "\n",
    "print(f'Tokenize the first sentence: \\n {tokenized_texts[0]}')\n",
    "print (f'\\nTokenize the first document: \\n {tokenized_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of sequences\n",
    "len_queries = [len(x) for x in tokenized_texts]\n",
    "len_documents = [len(x) for x in tokenized_docs]\n",
    "\n",
    "# Plot length of queries and documents\n",
    "n_bins = 20\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(len_queries, bins=n_bins)\n",
    "axs[0].set_title('Queries length',fontsize=12)\n",
    "axs[1].hist(len_documents, bins=n_bins)\n",
    "axs[1].set_title('Document length',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eye-balling the plot we determine to set maximum sequence length of queries to 24 and documents to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query ids:\n",
      " q_input_ids.shape = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum query length. \n",
    "MAX_LEN_Q = 24\n",
    "\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "q_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "q_input_ids = pad_sequences(q_input_ids, maxlen=MAX_LEN_Q, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of query ids:\\n q_input_ids.shape = {q_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query attention mask:\n",
      " q_attention_masks = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create query attention masks\n",
    "q_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in q_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  q_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of query attention mask:\\n q_attention_masks = {np.shape(q_attention_masks)}')\n",
    "\n",
    "assert q_input_ids.shape == np.shape(q_attention_masks), 'dimensions of q_input_ids and q_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids.shape: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum document length. \n",
    "MAX_LEN_DOC = 128\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_docs]\n",
    "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN_DOC, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of input_ids.shape: {d_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of d_attention_masks: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks for documents\n",
    "d_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in d_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  d_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of d_attention_masks: {np.shape(d_attention_masks)}')\n",
    "\n",
    "assert d_input_ids.shape == np.shape(d_attention_masks), 'dimensions of document d_input_ids and d_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model\n",
    "Queries and documents have now been tokenized to the vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "\n",
    "config = BertConfig.from_pretrained(model_path + r'\\bert_config.json')\n",
    "bert_base = BertModel(config)\n",
    "\n",
    "#param_optimizer = list(bert_base.named_parameters())\n",
    "#print(bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.bert = bert_base \n",
    "          ### New layers:\n",
    "          #TODO: self.finalLinear = nn.Linear(768, 32) # 32 is \"low\" for faster computation of MaxSim (it is independent of sequence lentgh)\n",
    "          \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "          sequence_output, pooled_output = self.bert(ids, attention_mask=mask) # sequence_output shape is: (batch_size, sequence_length, 768)\n",
    "               \n",
    "          # We apply the linear layer in line with ColBERT paper. The linear layer (which applies a linear transformation)\n",
    "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
    "          # a single token in the input sequence) and outputs 32 numbers for every token\n",
    "          # so the logits are of shape (batch_size, sequence_length, 32)\n",
    "          \n",
    "          #TODO: sequence_output = self.finalLinear(sequence_output)\n",
    "          sequence_output = F.softmax(sequence_output, dim=1)\n",
    "\n",
    "          #linear2_output = self.linear2(linear2_output)\n",
    "\n",
    "          return sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try model on first 10 query and document pairs\n",
    "sample_size = 80\n",
    "np.random.seed(seed=741)\n",
    "samples = np.random.randint(0,len(df),sample_size)\n",
    "\n",
    "q_id    = torch.tensor(q_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "q_mask  = torch.tensor(q_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "\n",
    "d_id    = torch.tensor(d_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "d_mask  = torch.tensor(d_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding size:     torch.Size([80, 24, 768])\n",
      "Document embedding size:  torch.Size([80, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "#bert_base.to(torch.device(device))\n",
    "my_model  = CustomBERTModel()\n",
    "my_model.to(torch.device(device))\n",
    "\n",
    "# Embeddings of queries\n",
    "q_outputs = my_model(q_id, mask=q_mask)\n",
    "\n",
    "# Embeddings of documents\n",
    "d_outputs = my_model(d_id, mask=d_mask)\n",
    "\n",
    "#With bert_base shape is: torch.Size([batch_size, 24, 768]) and torch.Size([batch_size, 128, 768])\n",
    "print('Query embedding size:    ', q_outputs.shape) \n",
    "print('Document embedding size: ', d_outputs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, given a query sequence $q = q_0 q_1...q_l$ and a document sequence $d = d_0 d_1...d_n$, we compute the bags of embeddings $E_q$ and $E_d$ in the following manner:\n",
    "\n",
    "* $E_q$ := Normalize( CNN( BERT(“[Q]$q_0 q_1...q_l$ ##...#”) ) )\n",
    "\n",
    "* $E_d$ := Normalize( CNN( BERT(“[D]$d_0 d_1...d_l$ ...d_n”) ) )\n",
    "\n",
    "where '#' refers to the [mask] tokens. In my implementation of ColBERT the output dimensions are as follow:\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_d) = [ 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    dim(E_Q) = [batch_{size} \\times 24 \\times 32] \\\\\n",
    "    dim(E_D) = [batch_{size} \\times 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The relevancy score, MaxSim, is defined as follows:\n",
    "\n",
    "$$ S_{q,d} = \\sum_{i \\in ||E_q||} \\max_{j \\in ||E_d||} E_{q_i} * E_{d_j}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MaxSim(q, D):\n",
    "    '''Takes in a query, q, and return it's similarity score to\n",
    "        all documents in  D.'''\n",
    "\n",
    "    # repeat q for faster matrix multiplication (faster than loop)\n",
    "    batch_size=D.shape[0]\n",
    "    q_X = q.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    # multiply the same query q against all documents (in D)\n",
    "    batch_mm = torch.bmm(q_X, D.permute(0,2,1))\n",
    "    \n",
    "    maks, _ = torch.max(batch_mm, dim=2) # dim=1 or dim=2\n",
    "    \n",
    "    # Sum over maximum values --> return vector of length len(D)\n",
    "    S_qD = torch.sum(maks, dim=1)\n",
    "    \n",
    "    return S_qD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [00:00<00:01, 38.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0332, 0.0274, 0.0375,  ..., 0.0209, 0.0213, 0.0434],\n",
      "        [0.0865, 0.0545, 0.0279,  ..., 0.0194, 0.0103, 0.0456],\n",
      "        [0.0160, 0.0238, 0.0254,  ..., 0.0212, 0.1165, 0.0217],\n",
      "        ...,\n",
      "        [0.0136, 0.1002, 0.0356,  ..., 0.0271, 0.0211, 0.1125],\n",
      "        [0.0411, 0.0476, 0.0150,  ..., 0.0395, 0.0793, 0.0554],\n",
      "        [0.0224, 0.0586, 0.0180,  ..., 0.0731, 0.0307, 0.0145]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1870, 0.0243, 0.0752,  ..., 0.0090, 0.0642, 0.0374],\n",
      "        [0.0303, 0.0226, 0.0330,  ..., 0.0264, 0.0392, 0.0374],\n",
      "        [0.0105, 0.0153, 0.0443,  ..., 0.0163, 0.0799, 0.0298],\n",
      "        ...,\n",
      "        [0.0544, 0.0477, 0.0449,  ..., 0.0422, 0.0263, 0.0955],\n",
      "        [0.0458, 0.1061, 0.0178,  ..., 0.0537, 0.0697, 0.0670],\n",
      "        [0.0170, 0.0867, 0.0426,  ..., 0.0192, 0.0241, 0.0198]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0588, 0.0147, 0.0745,  ..., 0.0172, 0.0116, 0.0795],\n",
      "        [0.0320, 0.0407, 0.0230,  ..., 0.0233, 0.0172, 0.0126],\n",
      "        [0.0288, 0.0246, 0.0416,  ..., 0.0240, 0.0812, 0.0142],\n",
      "        ...,\n",
      "        [0.0468, 0.0817, 0.0355,  ..., 0.0273, 0.0520, 0.2147],\n",
      "        [0.0207, 0.0996, 0.0256,  ..., 0.0351, 0.0338, 0.1446],\n",
      "        [0.0306, 0.0202, 0.0440,  ..., 0.0591, 0.0358, 0.1040]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1128, 0.0582, 0.0436,  ..., 0.0329, 0.0164, 0.0848],\n",
      "        [0.0393, 0.0192, 0.0486,  ..., 0.0196, 0.0216, 0.0146],\n",
      "        [0.0125, 0.0517, 0.0392,  ..., 0.0164, 0.0295, 0.0236],\n",
      "        ...,\n",
      "        [0.0537, 0.1866, 0.0384,  ..., 0.0260, 0.0237, 0.0660],\n",
      "        [0.0223, 0.0605, 0.0379,  ..., 0.0258, 0.0182, 0.0577],\n",
      "        [0.0289, 0.0320, 0.0138,  ..., 0.1185, 0.1115, 0.0496]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0498, 0.0107, 0.0939,  ..., 0.0115, 0.0210, 0.0403],\n",
      "        [0.0191, 0.0065, 0.0303,  ..., 0.0186, 0.0115, 0.0195],\n",
      "        [0.0106, 0.0196, 0.0266,  ..., 0.0180, 0.0511, 0.0192],\n",
      "        ...,\n",
      "        [0.0395, 0.1230, 0.0260,  ..., 0.0296, 0.0274, 0.0764],\n",
      "        [0.0163, 0.0892, 0.0268,  ..., 0.0574, 0.0544, 0.0696],\n",
      "        [0.0189, 0.0135, 0.0393,  ..., 0.0240, 0.0527, 0.0453]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0449, 0.0255, 0.0899,  ..., 0.0178, 0.0322, 0.0718],\n",
      "        [0.0699, 0.0349, 0.0286,  ..., 0.0125, 0.0260, 0.0304],\n",
      "        [0.0380, 0.0153, 0.0324,  ..., 0.0651, 0.0773, 0.0313],\n",
      "        ...,\n",
      "        [0.0196, 0.1411, 0.0610,  ..., 0.0300, 0.0240, 0.0394],\n",
      "        [0.1501, 0.0596, 0.0249,  ..., 0.0220, 0.0309, 0.0981],\n",
      "        [0.0410, 0.0616, 0.0325,  ..., 0.0366, 0.0709, 0.0216]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1262, 0.0385, 0.0300,  ..., 0.0152, 0.0214, 0.0547],\n",
      "        [0.0254, 0.0316, 0.0174,  ..., 0.0344, 0.0123, 0.0212],\n",
      "        [0.0072, 0.0211, 0.0445,  ..., 0.0135, 0.0383, 0.0509],\n",
      "        ...,\n",
      "        [0.0266, 0.0690, 0.0313,  ..., 0.0185, 0.0240, 0.1090],\n",
      "        [0.0272, 0.0312, 0.0096,  ..., 0.0218, 0.0179, 0.0754],\n",
      "        [0.0329, 0.0488, 0.0819,  ..., 0.0551, 0.0592, 0.0546]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0878, 0.0395, 0.1327,  ..., 0.0457, 0.0241, 0.1301],\n",
      "        [0.0242, 0.0234, 0.0363,  ..., 0.0075, 0.0402, 0.0322],\n",
      "        [0.0114, 0.0207, 0.0378,  ..., 0.0310, 0.0767, 0.0185],\n",
      "        ...,\n",
      "        [0.0355, 0.0833, 0.0488,  ..., 0.0507, 0.0296, 0.0325],\n",
      "        [0.0254, 0.0343, 0.0372,  ..., 0.0445, 0.0647, 0.0912],\n",
      "        [0.0663, 0.0992, 0.0536,  ..., 0.0951, 0.0371, 0.0291]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0447, 0.0231, 0.0462,  ..., 0.0119, 0.0441, 0.0736],\n",
      "        [0.0246, 0.0398, 0.0546,  ..., 0.0093, 0.0175, 0.0476],\n",
      "        [0.0086, 0.0229, 0.0141,  ..., 0.0136, 0.0638, 0.0324],\n",
      "        ...,\n",
      "        [0.0366, 0.1073, 0.0368,  ..., 0.0213, 0.0483, 0.0506],\n",
      "        [0.0484, 0.0910, 0.0215,  ..., 0.0755, 0.0386, 0.0420],\n",
      "        [0.0590, 0.0701, 0.0153,  ..., 0.0518, 0.0349, 0.0360]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [00:00<00:01, 38.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.1031, 0.0192, 0.0690,  ..., 0.0330, 0.0350, 0.0541],\n",
      "        [0.0262, 0.0168, 0.0538,  ..., 0.0195, 0.0181, 0.0272],\n",
      "        [0.0105, 0.0227, 0.0534,  ..., 0.0270, 0.0413, 0.0209],\n",
      "        ...,\n",
      "        [0.0977, 0.0834, 0.0183,  ..., 0.0191, 0.0792, 0.0668],\n",
      "        [0.0449, 0.0683, 0.0142,  ..., 0.0592, 0.0524, 0.0431],\n",
      "        [0.0181, 0.0651, 0.0487,  ..., 0.0610, 0.0304, 0.0272]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0907, 0.0339, 0.0367,  ..., 0.0245, 0.0282, 0.0794],\n",
      "        [0.0610, 0.0419, 0.0405,  ..., 0.0347, 0.0201, 0.0228],\n",
      "        [0.0231, 0.0183, 0.0482,  ..., 0.0320, 0.0450, 0.0268],\n",
      "        ...,\n",
      "        [0.0286, 0.0597, 0.0218,  ..., 0.0271, 0.0242, 0.0857],\n",
      "        [0.0335, 0.0831, 0.0150,  ..., 0.0692, 0.0568, 0.0608],\n",
      "        [0.0741, 0.0168, 0.0449,  ..., 0.0612, 0.0520, 0.0422]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0719, 0.0242, 0.0798,  ..., 0.0209, 0.0166, 0.0768],\n",
      "        [0.0176, 0.0194, 0.0147,  ..., 0.0744, 0.0177, 0.0444],\n",
      "        [0.0080, 0.0166, 0.0168,  ..., 0.0438, 0.0635, 0.0221],\n",
      "        ...,\n",
      "        [0.0203, 0.0589, 0.0652,  ..., 0.0210, 0.0335, 0.0528],\n",
      "        [0.0203, 0.0294, 0.0230,  ..., 0.0246, 0.0309, 0.0714],\n",
      "        [0.1267, 0.0229, 0.0275,  ..., 0.0318, 0.1020, 0.0262]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0504, 0.0172, 0.0409,  ..., 0.0202, 0.0236, 0.0659],\n",
      "        [0.0088, 0.0317, 0.0349,  ..., 0.0208, 0.0154, 0.0258],\n",
      "        [0.0136, 0.0403, 0.0440,  ..., 0.0347, 0.0397, 0.0148],\n",
      "        ...,\n",
      "        [0.0363, 0.1132, 0.0361,  ..., 0.0402, 0.0464, 0.1022],\n",
      "        [0.0677, 0.1435, 0.0133,  ..., 0.0216, 0.0545, 0.0535],\n",
      "        [0.0433, 0.0545, 0.0157,  ..., 0.0340, 0.0684, 0.0273]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0382, 0.0313, 0.0590,  ..., 0.0199, 0.0185, 0.0642],\n",
      "        [0.0152, 0.0258, 0.0335,  ..., 0.0228, 0.0305, 0.0255],\n",
      "        [0.0146, 0.0163, 0.0245,  ..., 0.0157, 0.0422, 0.0200],\n",
      "        ...,\n",
      "        [0.0355, 0.1981, 0.0394,  ..., 0.0335, 0.0234, 0.1218],\n",
      "        [0.0711, 0.0600, 0.0183,  ..., 0.0376, 0.0347, 0.0548],\n",
      "        [0.0292, 0.0166, 0.0427,  ..., 0.0612, 0.0697, 0.0857]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0482, 0.0335, 0.0880,  ..., 0.0187, 0.0552, 0.0852],\n",
      "        [0.0560, 0.0637, 0.0647,  ..., 0.0358, 0.0114, 0.0165],\n",
      "        [0.0132, 0.0193, 0.0358,  ..., 0.0968, 0.0441, 0.0147],\n",
      "        ...,\n",
      "        [0.0274, 0.0800, 0.0332,  ..., 0.0220, 0.0525, 0.0442],\n",
      "        [0.0532, 0.0444, 0.0282,  ..., 0.0598, 0.0218, 0.0151],\n",
      "        [0.0452, 0.0210, 0.0621,  ..., 0.0559, 0.0598, 0.1035]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1258, 0.0309, 0.0493,  ..., 0.0203, 0.0152, 0.0249],\n",
      "        [0.0281, 0.0455, 0.0494,  ..., 0.0250, 0.0114, 0.0191],\n",
      "        [0.0099, 0.0272, 0.0675,  ..., 0.0376, 0.0491, 0.0204],\n",
      "        ...,\n",
      "        [0.0311, 0.0940, 0.0492,  ..., 0.0090, 0.0849, 0.1096],\n",
      "        [0.0184, 0.0405, 0.0262,  ..., 0.0295, 0.0118, 0.0331],\n",
      "        [0.0985, 0.0395, 0.0654,  ..., 0.0376, 0.0412, 0.0232]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [00:00<00:01, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.1012, 0.0173, 0.0252,  ..., 0.0412, 0.0353, 0.0624],\n",
      "        [0.0737, 0.0442, 0.0269,  ..., 0.0233, 0.0364, 0.0168],\n",
      "        [0.0120, 0.0244, 0.0330,  ..., 0.0181, 0.0528, 0.0073],\n",
      "        ...,\n",
      "        [0.0425, 0.0385, 0.0563,  ..., 0.0343, 0.0288, 0.0734],\n",
      "        [0.0650, 0.0705, 0.0431,  ..., 0.0308, 0.0633, 0.0441],\n",
      "        [0.0198, 0.0316, 0.0280,  ..., 0.0361, 0.0453, 0.0445]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0636, 0.0109, 0.1164,  ..., 0.0090, 0.0306, 0.0238],\n",
      "        [0.0494, 0.0805, 0.0263,  ..., 0.0527, 0.0238, 0.0647],\n",
      "        [0.0084, 0.0210, 0.0541,  ..., 0.0424, 0.0461, 0.0078],\n",
      "        ...,\n",
      "        [0.0356, 0.1962, 0.0378,  ..., 0.0626, 0.0258, 0.1045],\n",
      "        [0.0437, 0.0460, 0.0268,  ..., 0.0456, 0.0214, 0.1028],\n",
      "        [0.0296, 0.0790, 0.0368,  ..., 0.0493, 0.0957, 0.0466]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1230, 0.0175, 0.0701,  ..., 0.0249, 0.0273, 0.0816],\n",
      "        [0.0112, 0.0511, 0.0609,  ..., 0.0291, 0.0290, 0.0302],\n",
      "        [0.0336, 0.0168, 0.0444,  ..., 0.0141, 0.0498, 0.0385],\n",
      "        ...,\n",
      "        [0.0226, 0.0629, 0.0492,  ..., 0.0213, 0.0195, 0.0174],\n",
      "        [0.0206, 0.0499, 0.0174,  ..., 0.0403, 0.0283, 0.0532],\n",
      "        [0.0549, 0.0334, 0.0811,  ..., 0.0587, 0.0397, 0.0301]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1656, 0.0150, 0.0591,  ..., 0.0186, 0.0367, 0.0339],\n",
      "        [0.0351, 0.0264, 0.0259,  ..., 0.0195, 0.0161, 0.0304],\n",
      "        [0.0093, 0.0258, 0.0513,  ..., 0.0137, 0.0368, 0.0342],\n",
      "        ...,\n",
      "        [0.0426, 0.0477, 0.0401,  ..., 0.0216, 0.0685, 0.1618],\n",
      "        [0.0601, 0.0692, 0.0165,  ..., 0.0824, 0.0504, 0.0356],\n",
      "        [0.0431, 0.0279, 0.0910,  ..., 0.0793, 0.0287, 0.0260]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0836, 0.0250, 0.0510,  ..., 0.0339, 0.0312, 0.1631],\n",
      "        [0.0141, 0.0405, 0.0373,  ..., 0.0147, 0.0231, 0.0498],\n",
      "        [0.0089, 0.0116, 0.0386,  ..., 0.0160, 0.1012, 0.0070],\n",
      "        ...,\n",
      "        [0.0349, 0.0698, 0.0177,  ..., 0.0243, 0.0188, 0.0450],\n",
      "        [0.0311, 0.0460, 0.0236,  ..., 0.0313, 0.0689, 0.1005],\n",
      "        [0.0365, 0.0289, 0.0278,  ..., 0.0429, 0.0416, 0.0317]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0547, 0.0149, 0.0398,  ..., 0.0175, 0.0591, 0.0536],\n",
      "        [0.0537, 0.0352, 0.0299,  ..., 0.0181, 0.0208, 0.0194],\n",
      "        [0.0261, 0.0161, 0.0368,  ..., 0.0087, 0.0780, 0.0475],\n",
      "        ...,\n",
      "        [0.0303, 0.0642, 0.0472,  ..., 0.0154, 0.0286, 0.1625],\n",
      "        [0.0119, 0.1122, 0.0255,  ..., 0.0451, 0.0292, 0.0909],\n",
      "        [0.0378, 0.0925, 0.0484,  ..., 0.0558, 0.0375, 0.0271]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0546, 0.0308, 0.0742,  ..., 0.0221, 0.0283, 0.0660],\n",
      "        [0.0226, 0.0309, 0.0533,  ..., 0.0302, 0.0092, 0.0178],\n",
      "        [0.0092, 0.0765, 0.0247,  ..., 0.0267, 0.0593, 0.0149],\n",
      "        ...,\n",
      "        [0.0147, 0.1071, 0.0606,  ..., 0.0259, 0.0411, 0.0791],\n",
      "        [0.0650, 0.0247, 0.0363,  ..., 0.0685, 0.0484, 0.0553],\n",
      "        [0.0604, 0.0200, 0.0315,  ..., 0.0738, 0.0319, 0.0568]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0674, 0.0516, 0.0314,  ..., 0.0191, 0.0322, 0.0230],\n",
      "        [0.0300, 0.0398, 0.0328,  ..., 0.0169, 0.0130, 0.0349],\n",
      "        [0.0046, 0.0208, 0.0299,  ..., 0.0090, 0.0723, 0.0166],\n",
      "        ...,\n",
      "        [0.0395, 0.0783, 0.0123,  ..., 0.0548, 0.0231, 0.0863],\n",
      "        [0.0421, 0.0461, 0.0126,  ..., 0.0378, 0.0699, 0.0882],\n",
      "        [0.0379, 0.0971, 0.0373,  ..., 0.0307, 0.0535, 0.0365]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1285, 0.0226, 0.0285,  ..., 0.0149, 0.1066, 0.0318],\n",
      "        [0.0215, 0.0160, 0.0345,  ..., 0.0413, 0.0280, 0.0310],\n",
      "        [0.0122, 0.0388, 0.0581,  ..., 0.0261, 0.0483, 0.0157],\n",
      "        ...,\n",
      "        [0.0273, 0.1594, 0.0484,  ..., 0.0180, 0.0183, 0.0484],\n",
      "        [0.0382, 0.0616, 0.0361,  ..., 0.0457, 0.0688, 0.0470],\n",
      "        [0.0403, 0.0481, 0.0321,  ..., 0.0371, 0.0313, 0.0482]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [00:00<00:01, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.0562, 0.0145, 0.0546,  ..., 0.0116, 0.0209, 0.1657],\n",
      "        [0.0335, 0.0438, 0.0215,  ..., 0.0202, 0.0324, 0.0153],\n",
      "        [0.0076, 0.0359, 0.0690,  ..., 0.0104, 0.0567, 0.0132],\n",
      "        ...,\n",
      "        [0.0269, 0.0351, 0.0571,  ..., 0.0290, 0.0450, 0.1539],\n",
      "        [0.0190, 0.0292, 0.0178,  ..., 0.0599, 0.0913, 0.0399],\n",
      "        [0.1073, 0.0987, 0.0768,  ..., 0.0314, 0.0442, 0.0336]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1060, 0.0569, 0.0610,  ..., 0.0160, 0.0306, 0.0625],\n",
      "        [0.0234, 0.0296, 0.0174,  ..., 0.0215, 0.0194, 0.0260],\n",
      "        [0.0116, 0.0375, 0.0355,  ..., 0.0186, 0.0549, 0.0083],\n",
      "        ...,\n",
      "        [0.0347, 0.1209, 0.0329,  ..., 0.0431, 0.0304, 0.0509],\n",
      "        [0.0432, 0.0598, 0.0155,  ..., 0.0653, 0.0292, 0.0421],\n",
      "        [0.0253, 0.0628, 0.0566,  ..., 0.0682, 0.0462, 0.0347]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0545, 0.0243, 0.0559,  ..., 0.0243, 0.0319, 0.0418],\n",
      "        [0.0215, 0.0923, 0.0312,  ..., 0.0534, 0.0084, 0.0239],\n",
      "        [0.0126, 0.0165, 0.0597,  ..., 0.0209, 0.0621, 0.0238],\n",
      "        ...,\n",
      "        [0.0711, 0.0220, 0.0720,  ..., 0.0496, 0.0400, 0.1670],\n",
      "        [0.0377, 0.0945, 0.0197,  ..., 0.0320, 0.0487, 0.0504],\n",
      "        [0.0328, 0.0780, 0.0475,  ..., 0.0280, 0.0815, 0.0395]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0600, 0.0178, 0.0996,  ..., 0.0125, 0.0446, 0.0441],\n",
      "        [0.0191, 0.1163, 0.0185,  ..., 0.0494, 0.0189, 0.0239],\n",
      "        [0.0096, 0.0249, 0.0337,  ..., 0.0167, 0.0318, 0.0232],\n",
      "        ...,\n",
      "        [0.0620, 0.0681, 0.0556,  ..., 0.0345, 0.0425, 0.0868],\n",
      "        [0.0321, 0.0457, 0.0100,  ..., 0.0701, 0.0333, 0.0675],\n",
      "        [0.0391, 0.0383, 0.0247,  ..., 0.0399, 0.0451, 0.0456]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0683, 0.0585, 0.0377,  ..., 0.0378, 0.0210, 0.0916],\n",
      "        [0.0119, 0.0542, 0.0299,  ..., 0.0088, 0.0217, 0.0340],\n",
      "        [0.0306, 0.0141, 0.0515,  ..., 0.0244, 0.0914, 0.0183],\n",
      "        ...,\n",
      "        [0.0259, 0.0853, 0.0372,  ..., 0.0274, 0.0308, 0.1217],\n",
      "        [0.0621, 0.0552, 0.0160,  ..., 0.0472, 0.0274, 0.0406],\n",
      "        [0.0292, 0.0313, 0.0478,  ..., 0.0412, 0.0525, 0.0205]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1924, 0.0199, 0.0651,  ..., 0.0309, 0.0236, 0.0284],\n",
      "        [0.0280, 0.0478, 0.0221,  ..., 0.0208, 0.0194, 0.0372],\n",
      "        [0.0296, 0.0512, 0.0377,  ..., 0.0145, 0.0646, 0.0183],\n",
      "        ...,\n",
      "        [0.0490, 0.0819, 0.0390,  ..., 0.0287, 0.0213, 0.1576],\n",
      "        [0.0368, 0.0341, 0.0482,  ..., 0.0305, 0.0426, 0.0259],\n",
      "        [0.0186, 0.0591, 0.0436,  ..., 0.0175, 0.0548, 0.0436]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0561, 0.0206, 0.0511,  ..., 0.0143, 0.0289, 0.0508],\n",
      "        [0.0195, 0.0273, 0.0443,  ..., 0.0160, 0.0225, 0.0238],\n",
      "        [0.0177, 0.0083, 0.0262,  ..., 0.0123, 0.0449, 0.0146],\n",
      "        ...,\n",
      "        [0.0467, 0.0696, 0.0317,  ..., 0.0261, 0.0226, 0.0850],\n",
      "        [0.0275, 0.0644, 0.0265,  ..., 0.0368, 0.0516, 0.0916],\n",
      "        [0.0285, 0.0723, 0.0149,  ..., 0.0235, 0.0561, 0.0290]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0340, 0.0328, 0.0402,  ..., 0.0136, 0.0242, 0.0743],\n",
      "        [0.0236, 0.0259, 0.0720,  ..., 0.0403, 0.0292, 0.0704],\n",
      "        [0.0174, 0.0113, 0.0393,  ..., 0.0175, 0.0333, 0.0094],\n",
      "        ...,\n",
      "        [0.0585, 0.0689, 0.0299,  ..., 0.0179, 0.0405, 0.0738],\n",
      "        [0.0395, 0.0250, 0.0231,  ..., 0.0563, 0.0231, 0.0323],\n",
      "        [0.0212, 0.0386, 0.0244,  ..., 0.0996, 0.0436, 0.0327]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0855, 0.0215, 0.0461,  ..., 0.0162, 0.0445, 0.1348],\n",
      "        [0.0364, 0.0264, 0.0770,  ..., 0.0306, 0.0205, 0.0234],\n",
      "        [0.0133, 0.0065, 0.0402,  ..., 0.0171, 0.0455, 0.0212],\n",
      "        ...,\n",
      "        [0.0420, 0.0714, 0.0424,  ..., 0.0179, 0.0260, 0.1279],\n",
      "        [0.0273, 0.0333, 0.0346,  ..., 0.0421, 0.0440, 0.0111],\n",
      "        [0.0270, 0.0940, 0.0253,  ..., 0.0235, 0.0334, 0.0363]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [00:00<00:00, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0965, 0.0214, 0.0836,  ..., 0.0148, 0.0350, 0.0344],\n",
      "        [0.0761, 0.0443, 0.0397,  ..., 0.0283, 0.0148, 0.0222],\n",
      "        [0.0127, 0.0161, 0.0409,  ..., 0.0165, 0.0500, 0.0235],\n",
      "        ...,\n",
      "        [0.0134, 0.0786, 0.0763,  ..., 0.0263, 0.0388, 0.0666],\n",
      "        [0.0318, 0.0477, 0.0122,  ..., 0.0547, 0.0535, 0.0592],\n",
      "        [0.0550, 0.0471, 0.0229,  ..., 0.0722, 0.0500, 0.0479]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0891, 0.0255, 0.0902,  ..., 0.0279, 0.0227, 0.0591],\n",
      "        [0.0152, 0.0560, 0.0174,  ..., 0.0735, 0.0207, 0.0208],\n",
      "        [0.0042, 0.0402, 0.0298,  ..., 0.0125, 0.0547, 0.0340],\n",
      "        ...,\n",
      "        [0.0474, 0.0263, 0.0839,  ..., 0.0197, 0.0386, 0.0823],\n",
      "        [0.0268, 0.0468, 0.0196,  ..., 0.0377, 0.0466, 0.0628],\n",
      "        [0.0547, 0.1114, 0.0511,  ..., 0.0413, 0.0538, 0.0368]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0624, 0.0178, 0.0430,  ..., 0.0148, 0.0261, 0.0373],\n",
      "        [0.0212, 0.0381, 0.0367,  ..., 0.0260, 0.0360, 0.0357],\n",
      "        [0.0164, 0.0123, 0.0671,  ..., 0.0062, 0.0426, 0.0091],\n",
      "        ...,\n",
      "        [0.0411, 0.0571, 0.0581,  ..., 0.0287, 0.0211, 0.0621],\n",
      "        [0.0531, 0.0447, 0.0126,  ..., 0.0433, 0.0273, 0.0928],\n",
      "        [0.0524, 0.0765, 0.0589,  ..., 0.0776, 0.0218, 0.0382]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0342, 0.0129, 0.0934,  ..., 0.0410, 0.0252, 0.0516],\n",
      "        [0.0151, 0.0489, 0.0253,  ..., 0.0322, 0.0273, 0.0342],\n",
      "        [0.0229, 0.0522, 0.0213,  ..., 0.0144, 0.0364, 0.0241],\n",
      "        ...,\n",
      "        [0.0206, 0.0751, 0.0592,  ..., 0.0358, 0.0454, 0.1161],\n",
      "        [0.0832, 0.0287, 0.0066,  ..., 0.0327, 0.0319, 0.0781],\n",
      "        [0.0280, 0.0691, 0.0226,  ..., 0.0268, 0.0507, 0.0149]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0816, 0.0141, 0.0419,  ..., 0.0351, 0.0212, 0.0948],\n",
      "        [0.0221, 0.0537, 0.0224,  ..., 0.0591, 0.0093, 0.0207],\n",
      "        [0.0062, 0.0160, 0.0159,  ..., 0.0162, 0.0471, 0.0158],\n",
      "        ...,\n",
      "        [0.0644, 0.0617, 0.0728,  ..., 0.0410, 0.0347, 0.0303],\n",
      "        [0.0377, 0.0448, 0.0128,  ..., 0.0302, 0.0418, 0.1272],\n",
      "        [0.0209, 0.1111, 0.0210,  ..., 0.0443, 0.0838, 0.0533]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0812, 0.0174, 0.1029,  ..., 0.0207, 0.0142, 0.0938],\n",
      "        [0.0349, 0.0216, 0.0344,  ..., 0.0225, 0.0135, 0.0604],\n",
      "        [0.0270, 0.0262, 0.0536,  ..., 0.0578, 0.0939, 0.0541],\n",
      "        ...,\n",
      "        [0.0228, 0.1307, 0.0301,  ..., 0.0358, 0.0437, 0.0397],\n",
      "        [0.0566, 0.0215, 0.0269,  ..., 0.0259, 0.0214, 0.0468],\n",
      "        [0.0605, 0.0503, 0.0409,  ..., 0.0344, 0.0655, 0.0077]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0628, 0.0231, 0.0514,  ..., 0.0340, 0.0849, 0.1086],\n",
      "        [0.0223, 0.0301, 0.0559,  ..., 0.0420, 0.0194, 0.0342],\n",
      "        [0.0129, 0.0227, 0.0261,  ..., 0.0110, 0.0319, 0.0139],\n",
      "        ...,\n",
      "        [0.1443, 0.0736, 0.0688,  ..., 0.0271, 0.0542, 0.0240],\n",
      "        [0.0201, 0.0814, 0.0321,  ..., 0.0960, 0.0275, 0.0292],\n",
      "        [0.0441, 0.0295, 0.0922,  ..., 0.0219, 0.0624, 0.0152]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1260, 0.0140, 0.0563,  ..., 0.0338, 0.0243, 0.0345],\n",
      "        [0.0103, 0.0559, 0.0382,  ..., 0.0337, 0.0193, 0.0338],\n",
      "        [0.0119, 0.0153, 0.0344,  ..., 0.0277, 0.0402, 0.0288],\n",
      "        ...,\n",
      "        [0.0439, 0.1059, 0.0867,  ..., 0.0237, 0.0435, 0.0668],\n",
      "        [0.0374, 0.0963, 0.0352,  ..., 0.0659, 0.0441, 0.0794],\n",
      "        [0.0327, 0.0722, 0.0284,  ..., 0.0293, 0.0524, 0.0244]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0569, 0.0179, 0.0839,  ..., 0.0164, 0.0211, 0.0904],\n",
      "        [0.0425, 0.0426, 0.0621,  ..., 0.0186, 0.0246, 0.0286],\n",
      "        [0.0098, 0.0250, 0.0315,  ..., 0.0248, 0.0324, 0.0223],\n",
      "        ...,\n",
      "        [0.0230, 0.0547, 0.0465,  ..., 0.0375, 0.0383, 0.0301],\n",
      "        [0.0464, 0.0450, 0.0237,  ..., 0.0287, 0.0390, 0.0604],\n",
      "        [0.0476, 0.0808, 0.0635,  ..., 0.0396, 0.0944, 0.0831]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [00:01<00:00, 50.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.1114, 0.0247, 0.1001,  ..., 0.0231, 0.0139, 0.0533],\n",
      "        [0.0170, 0.0382, 0.0370,  ..., 0.0204, 0.0209, 0.0553],\n",
      "        [0.0105, 0.0251, 0.0356,  ..., 0.0234, 0.0636, 0.0203],\n",
      "        ...,\n",
      "        [0.0579, 0.0561, 0.0519,  ..., 0.0203, 0.0260, 0.0697],\n",
      "        [0.0317, 0.0791, 0.0158,  ..., 0.0692, 0.0980, 0.0664],\n",
      "        [0.0547, 0.0211, 0.0490,  ..., 0.0687, 0.0462, 0.0740]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0755, 0.0231, 0.0517,  ..., 0.0320, 0.0217, 0.0415],\n",
      "        [0.0338, 0.0217, 0.0256,  ..., 0.0414, 0.0204, 0.0614],\n",
      "        [0.0274, 0.0161, 0.0505,  ..., 0.0156, 0.0259, 0.0255],\n",
      "        ...,\n",
      "        [0.0377, 0.0719, 0.0661,  ..., 0.0242, 0.0188, 0.0566],\n",
      "        [0.0448, 0.0234, 0.0188,  ..., 0.0628, 0.0360, 0.0527],\n",
      "        [0.0764, 0.0616, 0.0289,  ..., 0.0176, 0.0454, 0.0663]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1089, 0.0290, 0.0703,  ..., 0.0217, 0.0212, 0.0701],\n",
      "        [0.0442, 0.0263, 0.0505,  ..., 0.0266, 0.0218, 0.0581],\n",
      "        [0.0179, 0.0172, 0.0363,  ..., 0.0186, 0.0724, 0.0125],\n",
      "        ...,\n",
      "        [0.0399, 0.0446, 0.0603,  ..., 0.0301, 0.0227, 0.0854],\n",
      "        [0.0257, 0.0620, 0.0129,  ..., 0.0429, 0.0712, 0.0734],\n",
      "        [0.0341, 0.0529, 0.0569,  ..., 0.0782, 0.0345, 0.0466]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1235, 0.0312, 0.0808,  ..., 0.0143, 0.0173, 0.0354],\n",
      "        [0.0373, 0.0512, 0.0221,  ..., 0.0205, 0.0120, 0.0150],\n",
      "        [0.0110, 0.0172, 0.0526,  ..., 0.0381, 0.0546, 0.0181],\n",
      "        ...,\n",
      "        [0.0500, 0.0606, 0.0423,  ..., 0.0386, 0.0305, 0.0309],\n",
      "        [0.0420, 0.0276, 0.0419,  ..., 0.0430, 0.0397, 0.0385],\n",
      "        [0.0244, 0.0637, 0.0586,  ..., 0.0317, 0.0788, 0.0356]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0567, 0.0259, 0.0777,  ..., 0.0284, 0.0352, 0.0590],\n",
      "        [0.0167, 0.0437, 0.0122,  ..., 0.0252, 0.0124, 0.0094],\n",
      "        [0.0415, 0.0267, 0.0366,  ..., 0.0165, 0.0517, 0.0152],\n",
      "        ...,\n",
      "        [0.0234, 0.0578, 0.0405,  ..., 0.0138, 0.0594, 0.0613],\n",
      "        [0.1287, 0.0761, 0.0289,  ..., 0.0366, 0.0431, 0.1008],\n",
      "        [0.0936, 0.0550, 0.0789,  ..., 0.0188, 0.0187, 0.0357]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1438, 0.0192, 0.0543,  ..., 0.0242, 0.0205, 0.1000],\n",
      "        [0.0198, 0.0289, 0.0708,  ..., 0.0205, 0.0130, 0.0115],\n",
      "        [0.0214, 0.0286, 0.0317,  ..., 0.0332, 0.0878, 0.0301],\n",
      "        ...,\n",
      "        [0.0526, 0.0430, 0.0569,  ..., 0.0321, 0.0235, 0.1070],\n",
      "        [0.0329, 0.0600, 0.0343,  ..., 0.0466, 0.0394, 0.0603],\n",
      "        [0.0512, 0.0640, 0.0423,  ..., 0.0356, 0.0668, 0.0100]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0563, 0.0192, 0.0634,  ..., 0.0348, 0.0186, 0.0456],\n",
      "        [0.0263, 0.0200, 0.0439,  ..., 0.0148, 0.0209, 0.0207],\n",
      "        [0.0166, 0.0177, 0.0348,  ..., 0.0248, 0.0834, 0.0172],\n",
      "        ...,\n",
      "        [0.0536, 0.1770, 0.0395,  ..., 0.0186, 0.0469, 0.0612],\n",
      "        [0.0324, 0.0399, 0.0101,  ..., 0.0918, 0.0481, 0.0556],\n",
      "        [0.0475, 0.0367, 0.0286,  ..., 0.0472, 0.0593, 0.0916]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0734, 0.0322, 0.0411,  ..., 0.0372, 0.0177, 0.0857],\n",
      "        [0.0253, 0.0597, 0.0251,  ..., 0.0248, 0.0207, 0.0309],\n",
      "        [0.0238, 0.0156, 0.0355,  ..., 0.0249, 0.0782, 0.0191],\n",
      "        ...,\n",
      "        [0.0338, 0.1026, 0.0496,  ..., 0.0288, 0.0420, 0.0705],\n",
      "        [0.0432, 0.0545, 0.0097,  ..., 0.0221, 0.0435, 0.0501],\n",
      "        [0.0506, 0.0396, 0.0453,  ..., 0.0792, 0.0247, 0.0396]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0353, 0.0223, 0.0453,  ..., 0.0154, 0.0409, 0.0180],\n",
      "        [0.0308, 0.0271, 0.0448,  ..., 0.0253, 0.0199, 0.0276],\n",
      "        [0.0157, 0.0323, 0.0428,  ..., 0.0357, 0.0540, 0.0160],\n",
      "        ...,\n",
      "        [0.0255, 0.0612, 0.0406,  ..., 0.0305, 0.0354, 0.0610],\n",
      "        [0.0433, 0.0738, 0.0192,  ..., 0.0439, 0.0599, 0.0567],\n",
      "        [0.0391, 0.0486, 0.0660,  ..., 0.0224, 0.0588, 0.0630]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [00:01<00:00, 44.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.0907, 0.0217, 0.0836,  ..., 0.0188, 0.0158, 0.0983],\n",
      "        [0.0337, 0.0483, 0.0465,  ..., 0.0182, 0.0517, 0.0119],\n",
      "        [0.0171, 0.0186, 0.0421,  ..., 0.0199, 0.0491, 0.0145],\n",
      "        ...,\n",
      "        [0.0258, 0.1135, 0.0304,  ..., 0.0186, 0.0329, 0.0620],\n",
      "        [0.0542, 0.0516, 0.0176,  ..., 0.0728, 0.0327, 0.0782],\n",
      "        [0.0245, 0.1639, 0.0484,  ..., 0.0474, 0.0713, 0.0252]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0694, 0.0244, 0.0736,  ..., 0.0354, 0.0101, 0.0455],\n",
      "        [0.0319, 0.0214, 0.0373,  ..., 0.0079, 0.0790, 0.0756],\n",
      "        [0.0154, 0.0153, 0.0645,  ..., 0.0113, 0.0784, 0.0156],\n",
      "        ...,\n",
      "        [0.0810, 0.0893, 0.0399,  ..., 0.0478, 0.0199, 0.1409],\n",
      "        [0.0326, 0.0688, 0.0153,  ..., 0.0600, 0.0476, 0.0447],\n",
      "        [0.0208, 0.1086, 0.0243,  ..., 0.0434, 0.0381, 0.0399]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0386, 0.0246, 0.0743,  ..., 0.0408, 0.0351, 0.0688],\n",
      "        [0.0362, 0.0474, 0.0426,  ..., 0.0227, 0.0314, 0.0448],\n",
      "        [0.0130, 0.0099, 0.0449,  ..., 0.0086, 0.0305, 0.0448],\n",
      "        ...,\n",
      "        [0.0296, 0.0386, 0.0373,  ..., 0.0373, 0.0219, 0.0257],\n",
      "        [0.0846, 0.0799, 0.0233,  ..., 0.0258, 0.0239, 0.0778],\n",
      "        [0.0323, 0.0507, 0.0351,  ..., 0.0440, 0.0401, 0.0595]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0555, 0.0284, 0.0271,  ..., 0.0128, 0.0354, 0.1222],\n",
      "        [0.0227, 0.0128, 0.0381,  ..., 0.0139, 0.0106, 0.0274],\n",
      "        [0.0075, 0.0285, 0.0242,  ..., 0.0139, 0.0400, 0.0059],\n",
      "        ...,\n",
      "        [0.0467, 0.1237, 0.0683,  ..., 0.0315, 0.0329, 0.0630],\n",
      "        [0.0484, 0.0777, 0.0169,  ..., 0.0177, 0.0494, 0.0524],\n",
      "        [0.0348, 0.0558, 0.0242,  ..., 0.0718, 0.0658, 0.0286]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0542, 0.0225, 0.0843,  ..., 0.0134, 0.0201, 0.0415],\n",
      "        [0.0364, 0.0417, 0.0324,  ..., 0.0456, 0.0238, 0.0193],\n",
      "        [0.0125, 0.0164, 0.0305,  ..., 0.0179, 0.0259, 0.0093],\n",
      "        ...,\n",
      "        [0.0309, 0.2094, 0.0814,  ..., 0.0231, 0.0305, 0.0874],\n",
      "        [0.0350, 0.0185, 0.0221,  ..., 0.0280, 0.0326, 0.0723],\n",
      "        [0.0420, 0.0249, 0.0285,  ..., 0.0449, 0.0403, 0.0394]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:01<00:00, 40.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1441, 0.0068, 0.1256,  ..., 0.0175, 0.0466, 0.0423],\n",
      "        [0.0526, 0.0175, 0.0309,  ..., 0.0403, 0.0104, 0.0241],\n",
      "        [0.0080, 0.0356, 0.0234,  ..., 0.0119, 0.0268, 0.0168],\n",
      "        ...,\n",
      "        [0.0262, 0.0592, 0.0159,  ..., 0.0221, 0.0549, 0.1302],\n",
      "        [0.0457, 0.0576, 0.0198,  ..., 0.0465, 0.0524, 0.0910],\n",
      "        [0.0660, 0.0245, 0.0473,  ..., 0.0471, 0.0415, 0.0642]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0334, 0.0153, 0.0909,  ..., 0.0400, 0.0155, 0.0986],\n",
      "        [0.0287, 0.0560, 0.0201,  ..., 0.0614, 0.0157, 0.0199],\n",
      "        [0.0118, 0.0182, 0.0284,  ..., 0.0333, 0.0632, 0.0130],\n",
      "        ...,\n",
      "        [0.0478, 0.1642, 0.0694,  ..., 0.0281, 0.0316, 0.1430],\n",
      "        [0.0671, 0.0745, 0.0305,  ..., 0.0313, 0.1053, 0.0615],\n",
      "        [0.0428, 0.0296, 0.0383,  ..., 0.0358, 0.0454, 0.0525]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0753, 0.0256, 0.0592,  ..., 0.0248, 0.0355, 0.0546],\n",
      "        [0.0181, 0.0247, 0.0230,  ..., 0.0335, 0.0258, 0.0576],\n",
      "        [0.0212, 0.0202, 0.0288,  ..., 0.0277, 0.0552, 0.0179],\n",
      "        ...,\n",
      "        [0.0833, 0.0612, 0.0557,  ..., 0.0311, 0.0200, 0.0610],\n",
      "        [0.0478, 0.0515, 0.0298,  ..., 0.0234, 0.0391, 0.0425],\n",
      "        [0.0194, 0.0357, 0.0648,  ..., 0.0337, 0.0514, 0.0322]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0603, 0.0187, 0.0308,  ..., 0.0127, 0.0327, 0.0961],\n",
      "        [0.0296, 0.0572, 0.0494,  ..., 0.0216, 0.0689, 0.0204],\n",
      "        [0.0185, 0.0228, 0.0299,  ..., 0.0219, 0.0382, 0.0057],\n",
      "        ...,\n",
      "        [0.0461, 0.1422, 0.0430,  ..., 0.0483, 0.0309, 0.1128],\n",
      "        [0.0339, 0.0455, 0.0367,  ..., 0.0452, 0.0410, 0.1241],\n",
      "        [0.0526, 0.0557, 0.0657,  ..., 0.0566, 0.0380, 0.0425]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1242, 0.0360, 0.0644,  ..., 0.0214, 0.0213, 0.1049],\n",
      "        [0.0472, 0.0295, 0.0296,  ..., 0.0239, 0.0170, 0.0320],\n",
      "        [0.0127, 0.0124, 0.0222,  ..., 0.0249, 0.0627, 0.0117],\n",
      "        ...,\n",
      "        [0.0831, 0.0457, 0.0224,  ..., 0.0439, 0.0299, 0.0194],\n",
      "        [0.0783, 0.0613, 0.0132,  ..., 0.0492, 0.0247, 0.0717],\n",
      "        [0.0188, 0.0424, 0.0409,  ..., 0.0645, 0.0504, 0.0425]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0560, 0.0434, 0.0564,  ..., 0.0424, 0.0436, 0.0770],\n",
      "        [0.0736, 0.0738, 0.0206,  ..., 0.0271, 0.0232, 0.0250],\n",
      "        [0.0099, 0.0206, 0.0388,  ..., 0.0153, 0.0325, 0.0359],\n",
      "        ...,\n",
      "        [0.0244, 0.0563, 0.0676,  ..., 0.0563, 0.0305, 0.0823],\n",
      "        [0.0325, 0.0873, 0.0176,  ..., 0.0292, 0.0404, 0.0709],\n",
      "        [0.0203, 0.1289, 0.0410,  ..., 0.0376, 0.0382, 0.0322]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1927, 0.0304, 0.0978,  ..., 0.0184, 0.0323, 0.0509],\n",
      "        [0.0409, 0.0177, 0.0516,  ..., 0.0266, 0.0131, 0.0296],\n",
      "        [0.0097, 0.0154, 0.0260,  ..., 0.0169, 0.0284, 0.0228],\n",
      "        ...,\n",
      "        [0.0233, 0.1524, 0.0477,  ..., 0.0143, 0.0146, 0.0929],\n",
      "        [0.0561, 0.0382, 0.0525,  ..., 0.0352, 0.0743, 0.0556],\n",
      "        [0.0578, 0.0246, 0.0643,  ..., 0.0325, 0.0443, 0.0509]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0766, 0.0223, 0.0321,  ..., 0.0206, 0.0382, 0.0738],\n",
      "        [0.0171, 0.0246, 0.0093,  ..., 0.0267, 0.0300, 0.0348],\n",
      "        [0.0144, 0.0181, 0.0243,  ..., 0.0150, 0.0611, 0.0068],\n",
      "        ...,\n",
      "        [0.0497, 0.1059, 0.0353,  ..., 0.0278, 0.0651, 0.1783],\n",
      "        [0.0118, 0.0372, 0.0364,  ..., 0.0278, 0.0365, 0.0572],\n",
      "        [0.0197, 0.0562, 0.0223,  ..., 0.0420, 0.0791, 0.0189]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0688, 0.0133, 0.0401,  ..., 0.0132, 0.0176, 0.0888],\n",
      "        [0.0387, 0.0578, 0.0347,  ..., 0.0291, 0.0139, 0.0322],\n",
      "        [0.0135, 0.0227, 0.0236,  ..., 0.0119, 0.0955, 0.0334],\n",
      "        ...,\n",
      "        [0.0430, 0.0585, 0.0465,  ..., 0.0208, 0.0426, 0.0586],\n",
      "        [0.0790, 0.0574, 0.0291,  ..., 0.1053, 0.0200, 0.0733],\n",
      "        [0.0391, 0.0396, 0.0313,  ..., 0.0393, 0.0806, 0.0357]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1329, 0.0239, 0.0686,  ..., 0.0174, 0.0132, 0.1472],\n",
      "        [0.0336, 0.0342, 0.0608,  ..., 0.0348, 0.0118, 0.0321],\n",
      "        [0.0110, 0.0260, 0.0287,  ..., 0.0147, 0.0756, 0.0119],\n",
      "        ...,\n",
      "        [0.0299, 0.1643, 0.0344,  ..., 0.0324, 0.0281, 0.0720],\n",
      "        [0.0354, 0.0385, 0.0102,  ..., 0.0349, 0.0264, 0.0254],\n",
      "        [0.0173, 0.0669, 0.0302,  ..., 0.0842, 0.0373, 0.0112]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [00:01<00:00, 47.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.0479, 0.0281, 0.0586,  ..., 0.0442, 0.0511, 0.0634],\n",
      "        [0.0224, 0.0277, 0.0546,  ..., 0.0287, 0.0245, 0.0496],\n",
      "        [0.0065, 0.0236, 0.0224,  ..., 0.0227, 0.0672, 0.0094],\n",
      "        ...,\n",
      "        [0.0586, 0.1233, 0.0725,  ..., 0.0536, 0.0496, 0.1074],\n",
      "        [0.0408, 0.0622, 0.0322,  ..., 0.0941, 0.0353, 0.0462],\n",
      "        [0.0424, 0.0662, 0.0282,  ..., 0.0456, 0.0406, 0.0213]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0536, 0.0087, 0.0731,  ..., 0.0121, 0.0299, 0.0841],\n",
      "        [0.0212, 0.0367, 0.0403,  ..., 0.0373, 0.0096, 0.0280],\n",
      "        [0.0052, 0.0118, 0.0319,  ..., 0.0147, 0.0556, 0.0164],\n",
      "        ...,\n",
      "        [0.0215, 0.1177, 0.0568,  ..., 0.0568, 0.0325, 0.0551],\n",
      "        [0.1206, 0.0520, 0.0125,  ..., 0.0215, 0.0293, 0.0423],\n",
      "        [0.0752, 0.0977, 0.0456,  ..., 0.0517, 0.0605, 0.0181]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0836, 0.0335, 0.0658,  ..., 0.0392, 0.0290, 0.0603],\n",
      "        [0.0198, 0.0489, 0.0172,  ..., 0.0180, 0.0180, 0.0280],\n",
      "        [0.0122, 0.0106, 0.0379,  ..., 0.0140, 0.0363, 0.0133],\n",
      "        ...,\n",
      "        [0.0447, 0.0793, 0.0774,  ..., 0.0244, 0.0419, 0.0918],\n",
      "        [0.0257, 0.0656, 0.0148,  ..., 0.0443, 0.0289, 0.0790],\n",
      "        [0.0572, 0.0782, 0.0491,  ..., 0.0578, 0.0718, 0.0562]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0447, 0.0184, 0.0825,  ..., 0.0612, 0.0191, 0.0504],\n",
      "        [0.0107, 0.0191, 0.0119,  ..., 0.0270, 0.0358, 0.0463],\n",
      "        [0.0125, 0.0193, 0.0528,  ..., 0.0413, 0.0453, 0.0101],\n",
      "        ...,\n",
      "        [0.0464, 0.0689, 0.0696,  ..., 0.0328, 0.0179, 0.1029],\n",
      "        [0.0615, 0.0332, 0.0251,  ..., 0.0651, 0.0266, 0.0351],\n",
      "        [0.0237, 0.0645, 0.0266,  ..., 0.0301, 0.0294, 0.0097]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1215, 0.0274, 0.0484,  ..., 0.0183, 0.0100, 0.0697],\n",
      "        [0.1125, 0.0256, 0.0291,  ..., 0.0157, 0.0142, 0.0471],\n",
      "        [0.0096, 0.0266, 0.0175,  ..., 0.0229, 0.0682, 0.0280],\n",
      "        ...,\n",
      "        [0.0268, 0.0950, 0.0506,  ..., 0.0212, 0.0522, 0.0340],\n",
      "        [0.0403, 0.0685, 0.0163,  ..., 0.0554, 0.0374, 0.0434],\n",
      "        [0.0232, 0.0304, 0.0485,  ..., 0.0268, 0.0280, 0.0352]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0535, 0.0195, 0.0750,  ..., 0.0164, 0.0263, 0.1011],\n",
      "        [0.0419, 0.0135, 0.0241,  ..., 0.0305, 0.0120, 0.0302],\n",
      "        [0.0161, 0.0078, 0.0587,  ..., 0.0154, 0.0428, 0.0231],\n",
      "        ...,\n",
      "        [0.0843, 0.0388, 0.0637,  ..., 0.0415, 0.0214, 0.0729],\n",
      "        [0.0555, 0.0272, 0.0383,  ..., 0.0370, 0.0399, 0.0997],\n",
      "        [0.0211, 0.1044, 0.0259,  ..., 0.0567, 0.0644, 0.0401]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1185, 0.0205, 0.0682,  ..., 0.0471, 0.0284, 0.0862],\n",
      "        [0.0356, 0.0223, 0.0213,  ..., 0.0083, 0.0134, 0.0284],\n",
      "        [0.0126, 0.0215, 0.0184,  ..., 0.0163, 0.0986, 0.0231],\n",
      "        ...,\n",
      "        [0.0238, 0.1258, 0.0674,  ..., 0.0327, 0.0270, 0.0880],\n",
      "        [0.0426, 0.0621, 0.0222,  ..., 0.0400, 0.0279, 0.0685],\n",
      "        [0.0549, 0.0542, 0.0244,  ..., 0.0791, 0.0497, 0.0532]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0274, 0.0329, 0.0822,  ..., 0.0175, 0.0174, 0.0974],\n",
      "        [0.0469, 0.0377, 0.0154,  ..., 0.0262, 0.0173, 0.0447],\n",
      "        [0.0224, 0.0493, 0.0437,  ..., 0.0180, 0.0387, 0.0329],\n",
      "        ...,\n",
      "        [0.0729, 0.0925, 0.0214,  ..., 0.0316, 0.0186, 0.0849],\n",
      "        [0.0430, 0.0509, 0.0161,  ..., 0.0961, 0.0428, 0.0394],\n",
      "        [0.0518, 0.0407, 0.0512,  ..., 0.0430, 0.0654, 0.0281]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0703, 0.0133, 0.0676,  ..., 0.0266, 0.0214, 0.0682],\n",
      "        [0.0196, 0.0643, 0.0162,  ..., 0.0256, 0.0194, 0.0273],\n",
      "        [0.0118, 0.0377, 0.0467,  ..., 0.0232, 0.0426, 0.0130],\n",
      "        ...,\n",
      "        [0.0458, 0.1426, 0.0825,  ..., 0.0435, 0.0328, 0.0539],\n",
      "        [0.0258, 0.0635, 0.0192,  ..., 0.0325, 0.0593, 0.0958],\n",
      "        [0.0411, 0.0304, 0.0397,  ..., 0.0357, 0.0229, 0.0422]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0609, 0.0343, 0.0694,  ..., 0.0225, 0.0218, 0.1102],\n",
      "        [0.0293, 0.0286, 0.0422,  ..., 0.0197, 0.0438, 0.0261],\n",
      "        [0.0228, 0.0315, 0.0447,  ..., 0.0148, 0.0888, 0.0210],\n",
      "        ...,\n",
      "        [0.0194, 0.0454, 0.0620,  ..., 0.0165, 0.0422, 0.0756],\n",
      "        [0.0506, 0.0564, 0.0206,  ..., 0.0248, 0.0407, 0.0739],\n",
      "        [0.0989, 0.0504, 0.0609,  ..., 0.0325, 0.0373, 0.0503]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.1375, 0.0295, 0.0475,  ..., 0.0243, 0.0344, 0.0715],\n",
      "        [0.0250, 0.0318, 0.0255,  ..., 0.0209, 0.0169, 0.0416],\n",
      "        [0.0178, 0.0251, 0.0167,  ..., 0.0205, 0.0433, 0.0097],\n",
      "        ...,\n",
      "        [0.0761, 0.0443, 0.0287,  ..., 0.0279, 0.0352, 0.0427],\n",
      "        [0.0164, 0.1154, 0.0265,  ..., 0.0507, 0.0395, 0.0413],\n",
      "        [0.0785, 0.0761, 0.0619,  ..., 0.0524, 0.0610, 0.0992]],\n",
      "       grad_fn=<SelectBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:01<00:00, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.1089, 0.0178, 0.0393,  ..., 0.0754, 0.0283, 0.0867],\n",
      "        [0.0248, 0.0167, 0.0604,  ..., 0.0162, 0.0335, 0.0308],\n",
      "        [0.0247, 0.0211, 0.0740,  ..., 0.0173, 0.0518, 0.0066],\n",
      "        ...,\n",
      "        [0.0537, 0.0893, 0.0548,  ..., 0.0304, 0.0322, 0.0710],\n",
      "        [0.0487, 0.0780, 0.0171,  ..., 0.0326, 0.0695, 0.0540],\n",
      "        [0.0511, 0.0612, 0.0610,  ..., 0.0708, 0.0397, 0.0379]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[0.0674, 0.0364, 0.0923,  ..., 0.0102, 0.0225, 0.1017],\n",
      "        [0.0153, 0.0388, 0.0235,  ..., 0.0211, 0.0207, 0.0329],\n",
      "        [0.0219, 0.0207, 0.0313,  ..., 0.0165, 0.1248, 0.0121],\n",
      "        ...,\n",
      "        [0.0431, 0.1735, 0.0696,  ..., 0.0775, 0.0401, 0.0834],\n",
      "        [0.0335, 0.0244, 0.0163,  ..., 0.0558, 0.0261, 0.0534],\n",
      "        [0.0233, 0.0474, 0.0456,  ..., 0.0430, 0.0463, 0.0775]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "most_similar_doc_score = []\n",
    "most_similar_docID = []\n",
    "\n",
    " # Define D as all documents:\n",
    "D = d_outputs\n",
    "\n",
    "for q_no in tqdm(range(sample_size)):\n",
    "    \n",
    "    # Select one query\n",
    "    q = q_outputs[q_no]\n",
    "\n",
    "    # Compute similarity scores for all \n",
    "    S_qD = MaxSim(q, D)\n",
    "    maks, maks_id = torch.max(S_qD, dim=0)\n",
    "\n",
    "    most_similar_doc_score.append(float(maks))\n",
    "    most_similar_docID.append(int(maks_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "plt.hist(most_similar_docID, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "q_IDs = [x for x in range(sample_size)]\n",
    "plt.scatter(q_IDs, most_similar_docID)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03787878787878788"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = q_IDs\n",
    "y_pred = most_similar_docID\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rights: 4 out of 80 \n",
      " 0.05% accuracy\n"
     ]
    }
   ],
   "source": [
    "rights = sum(np.array(y_true) == np.array(y_pred))\n",
    "wrongs = sum(np.array(y_true) != np.array(y_pred))\n",
    "\n",
    "print(f'rights: {rights} out of {rights+wrongs} \\n {rights/(rights+wrongs)}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>udnytte avancerede kliniske kompetencer</td>\n",
       "      <td>Anvende avancerede kliniske kompetencer i best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>udvikle et genoptræningsprogram</td>\n",
       "      <td>Udvikle et genoptræningsprogram med henblik på...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>foretage indkøb af reservedele</td>\n",
       "      <td>Bestille særlige dele til vedligeholdelse og r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bruge værktøj til glasindgravering</td>\n",
       "      <td>Bruge værktøj til gravering, som anvender stål...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      query  \\\n",
       "24  udnytte avancerede kliniske kompetencer   \n",
       "34          udvikle et genoptræningsprogram   \n",
       "49           foretage indkøb af reservedele   \n",
       "62       bruge værktøj til glasindgravering   \n",
       "\n",
       "                                            documents  \n",
       "24  Anvende avancerede kliniske kompetencer i best...  \n",
       "34  Udvikle et genoptræningsprogram med henblik på...  \n",
       "49  Bestille særlige dele til vedligeholdelse og r...  \n",
       "62  Bruge værktøj til gravering, som anvender stål...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = df.iloc[:sample_size,:].loc[(np.array(y_true) == np.array(y_pred))]\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bestille særlige dele til vedligeholdelse og reparation af en lang række køretøjer.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.documents[49]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62490302a320790e9096d978396a0f6884d50306ab9199b7a47371992da1d123"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('colbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

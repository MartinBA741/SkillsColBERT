{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate SkillsColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install pytorch-pretrained-bert pytorch-nlp keras scikit-learn matplotlib tensorflow\n",
    "\n",
    "#https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "    a) Dimensions of max function in MaxSim method function.\n",
    "        - max of column vectors in matrix OR max of row vectors in columns\n",
    "    b) Training of my ColBERT model\n",
    "        - [Q] and [D] in vocabulary\n",
    "        - Weights in additional linear layer of 32\n",
    "        - [MASK] as padding instead of [PAD]\n",
    "    c) How to save:\n",
    "        The model (in github)\n",
    "        The document embeddings\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lede musikalsk personale</td>\n",
       "      <td>Tildele og forvalte personaleopgaver på område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>føre tilsyn med fængselsprocedurer</td>\n",
       "      <td>Føre tilsyn med driften af et fængsel eller an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anvende antioppressiv praksis</td>\n",
       "      <td>Identificere undertrykkelse i samfund, økonomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kontrollere overensstemmelse med jernbaneforsk...</td>\n",
       "      <td>Inspicere rullende materiel, komponenter og sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identificere tilgængelige tjenester</td>\n",
       "      <td>Identificere de forskellige tjenester, der er ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                           lede musikalsk personale   \n",
       "1                 føre tilsyn med fængselsprocedurer   \n",
       "2                      anvende antioppressiv praksis   \n",
       "3  kontrollere overensstemmelse med jernbaneforsk...   \n",
       "4                identificere tilgængelige tjenester   \n",
       "\n",
       "                                           documents  \n",
       "0  Tildele og forvalte personaleopgaver på område...  \n",
       "1  Føre tilsyn med driften af et fængsel eller an...  \n",
       "2  Identificere undertrykkelse i samfund, økonomi...  \n",
       "3  Inspicere rullende materiel, komponenter og sy...  \n",
       "4  Identificere de forskellige tjenester, der er ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'.\\data\\skills_description.csv', sep='\\t', encoding='utf-8')\n",
    "df = df.rename(columns={'preferredLabel':'query', 'description': 'documents'})\n",
    "df = df[['query', 'documents']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu. Be patient...\n"
     ]
    }
   ],
   "source": [
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device==\"cuda\":\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)\n",
    "    print(f'Running on {device} with {n_gpu} number of GPUs')\n",
    "else:\n",
    "    print(f'Running on {device}. Be patient...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of query:\n",
      " [CLS] [Q] lede musikalsk personale [SEP]\n",
      "\n",
      "Example of document:\n",
      " [CLS] [D] Tildele og forvalte personaleopgaver på områder såsom instrumentering, bearbejdning, reproduktion af musik og stemmetræning. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add special ColBERT tokens to queries and documents\n",
    "queries = [\"[CLS] [Q] \" + query + \" [SEP]\" for query in df['query']]\n",
    "\n",
    "documents =  [\"[CLS] [D] \" + query + \" [SEP]\" for query in df['documents']]\n",
    "\n",
    "print(\"Example of query:\\n\", queries[0])\n",
    "print(\"\\nExample of document:\\n\", documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence: \n",
      " ['[CLS]', '[UNK]', 'q', '[UNK]', 'lede', 'musikalsk', 'personale', '[SEP]']\n",
      "\n",
      "Tokenize the first document: \n",
      " ['[CLS]', '[UNK]', 'd', '[UNK]', 'tildele', 'og', 'forvalt', '##e', 'personale', '##opgaver', 'pa', 'om', '##rad', '##er', 'sas', '##om', 'instrumenter', '##ing', ',', 'bearbejdning', ',', 'reproduktion', 'af', 'musik', 'og', 'stemme', '##træning', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with BERT tokenizer\n",
    "model_path = r'J:\\VOA\\MABI\\Deep Learning\\my_DTU_project\\Models\\danish_bert_uncased_v2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
    "\n",
    "#tokenize queries\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in queries]\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in documents]\n",
    "\n",
    "print(f'Tokenize the first sentence: \\n {tokenized_texts[0]}')\n",
    "print (f'\\nTokenize the first document: \\n {tokenized_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of sequences\n",
    "len_queries = [len(x) for x in tokenized_texts]\n",
    "len_documents = [len(x) for x in tokenized_docs]\n",
    "\n",
    "# Plot length of queries and documents\n",
    "n_bins = 20\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(len_queries, bins=n_bins)\n",
    "axs[0].set_title('Queries length',fontsize=12)\n",
    "axs[1].hist(len_documents, bins=n_bins)\n",
    "axs[1].set_title('Document length',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eye-balling the plot we determine to set maximum sequence length of queries to 24 and documents to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query ids:\n",
      " q_input_ids.shape = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum query length. \n",
    "MAX_LEN_Q = 24\n",
    "\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "q_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "q_input_ids = pad_sequences(q_input_ids, maxlen=MAX_LEN_Q, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of query ids:\\n q_input_ids.shape = {q_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query attention mask:\n",
      " q_attention_masks = (13485, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create query attention masks\n",
    "q_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in q_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  q_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of query attention mask:\\n q_attention_masks = {np.shape(q_attention_masks)}')\n",
    "\n",
    "assert q_input_ids.shape == np.shape(q_attention_masks), 'dimensions of q_input_ids and q_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids.shape: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum document length. \n",
    "MAX_LEN_DOC = 128\n",
    "# Pad our input tokens\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_docs]\n",
    "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN_DOC, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(f'Shape of input_ids.shape: {d_input_ids.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of d_attention_masks: (13485, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create attention masks for documents\n",
    "d_attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in d_input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  d_attention_masks.append(seq_mask)\n",
    "\n",
    "print(f'Shape of d_attention_masks: {np.shape(d_attention_masks)}')\n",
    "\n",
    "assert d_input_ids.shape == np.shape(d_attention_masks), 'dimensions of document d_input_ids and d_attention_mask do not match' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model\n",
    "Queries and documents have now been tokenized to the vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "\n",
    "config = BertConfig.from_pretrained(model_path + r'\\bert_config.json')\n",
    "bert_base = BertModel(config)\n",
    "\n",
    "#param_optimizer = list(bert_base.named_parameters())\n",
    "#print(bert_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SkillsColBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "          super(SkillsColBERT, self).__init__()\n",
    "          self.bert = bert_base \n",
    "          ### New layers:\n",
    "          #TODO: \n",
    "          # self.finalLinear = nn.Linear(768, 32) # 32 is \"low\" for faster computation of MaxSim (it is independent of sequence lentgh)\n",
    "          \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "          sequence_output, pooled_output = self.bert(ids, attention_mask=mask) # sequence_output shape is: (batch_size, sequence_length, 768)\n",
    "               \n",
    "          # We apply the linear layer in line with ColBERT paper. The linear layer (which applies a linear transformation)\n",
    "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
    "          # a single token in the input sequence) and outputs 32 numbers for every token\n",
    "          # so the logits are of shape (batch_size, sequence_length, 32)\n",
    "          \n",
    "          #TODO: \n",
    "          # sequence_output = self.finalLinear(sequence_output)\n",
    "          sequence_output = F.softmax(sequence_output, dim=1)\n",
    "\n",
    "          return sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try model on first X query and document pairs\n",
    "sample_size = 30\n",
    "np.random.seed(seed=741)\n",
    "samples = np.random.randint(0,len(df),sample_size)\n",
    "\n",
    "q_id    = torch.tensor(q_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "q_mask  = torch.tensor(q_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "\n",
    "d_id    = torch.tensor(d_input_ids[:sample_size]).to(torch.device(device)).to(torch.int64)\n",
    "d_mask  = torch.tensor(d_attention_masks[:sample_size]).to(torch.device(device)).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding size:     torch.Size([30, 24, 768])\n",
      "Document embedding size:  torch.Size([30, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "#bert_base.to(torch.device(device))\n",
    "my_model  = SkillsColBERT()\n",
    "my_model.to(torch.device(device))\n",
    "\n",
    "# Embeddings of queries\n",
    "q_outputs = my_model(q_id, mask=q_mask)\n",
    "\n",
    "# Embeddings of documents\n",
    "d_outputs = my_model(d_id, mask=d_mask)\n",
    "\n",
    "#With bert_base shape is: torch.Size([batch_size, 24, 768]) and torch.Size([batch_size, 128, 768])\n",
    "print('Query embedding size:    ', q_outputs.shape) \n",
    "print('Document embedding size: ', d_outputs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, given a query sequence $q = q_0 q_1...q_l$ and a document sequence $d = d_0 d_1...d_n$, we compute the bags of embeddings $E_q$ and $E_d$ in the following manner:\n",
    "\n",
    "* $E_q$ := Normalize( CNN( BERT(“[Q]$q_0 q_1...q_l$ ##...#”) ) )\n",
    "\n",
    "* $E_d$ := Normalize( CNN( BERT(“[D]$d_0 d_1...d_l$ ...d_n”) ) )\n",
    "\n",
    "where '#' refers to the [mask] tokens. In my implementation of ColBERT the output dimensions are as follow:\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_d) = [ 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    dim(E_q) = [24 \\times 32] \\\\\n",
    "    dim(E_D) = [13.485 \\times 128 \\times 32]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The relevancy score, MaxSim, is defined as follows:\n",
    "\n",
    "$$ S_{q,d} = \\sum_{i \\in ||E_q||} \\max_{j \\in ||E_d||} E_{q_i} * E_{d_j}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxSim(q, D):\n",
    "    '''Takes in the embeddings of a query, q, and all documents' embeddings, D.\n",
    "        Return a tensor of the query's similarity scores to all documents in D.'''\n",
    "\n",
    "    # repeat q for faster matrix multiplication (faster than loop)\n",
    "    batch_size=D.shape[0]\n",
    "    q_X = q.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    # multiply the same query q against all documents (in D)\n",
    "    batch_mm = torch.bmm(q_X, D.permute(0,2,1))\n",
    "    \n",
    "    maks, _ = torch.max(batch_mm, dim=2) # dim=1 or dim=2\n",
    "    \n",
    "    # Sum over maximum values --> return vector of length len(D)\n",
    "    S_qD = torch.sum(maks, dim=1)\n",
    "    \n",
    "    return S_qD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exampleof implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 118.73it/s]\n"
     ]
    }
   ],
   "source": [
    "most_similar_doc_score = []\n",
    "most_similar_docID = []\n",
    "\n",
    " # Define D as all documents:\n",
    "D = d_outputs\n",
    "\n",
    "for q_no in tqdm(range(sample_size)):\n",
    "    \n",
    "    # Select one query\n",
    "    q = q_outputs[q_no]\n",
    "\n",
    "    # Compute similarity scores for all \n",
    "    S_qD = MaxSim(q, D)\n",
    "    maks, maks_id = torch.max(S_qD, dim=0)\n",
    "\n",
    "    most_similar_doc_score.append(float(maks))\n",
    "    most_similar_docID.append(int(maks_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "plt.hist(most_similar_docID, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of \"predictions\"\n",
    "q_IDs = [x for x in range(sample_size)]\n",
    "plt.scatter(q_IDs, most_similar_docID)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_1score:  0.0378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = q_IDs\n",
    "y_pred = most_similar_docID\n",
    "\n",
    "print('f_1score: ', round(f1_score(y_true, y_pred, average='macro'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rights: 2 out of 30 \n",
      " 0.067% accuracy\n"
     ]
    }
   ],
   "source": [
    "rights = sum(np.array(y_true) == np.array(y_pred))\n",
    "wrongs = sum(np.array(y_true) != np.array(y_pred))\n",
    "\n",
    "print(f'rights: {rights} out of {rights+wrongs} \\n {np.round(rights/(rights+wrongs),3)}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>håndtere forespørgsler fra kunder vedrørende f...</td>\n",
       "      <td>Behandle anmodninger fra havnebrugere og kunde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>udnytte avancerede kliniske kompetencer</td>\n",
       "      <td>Anvende avancerede kliniske kompetencer i best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "23  håndtere forespørgsler fra kunder vedrørende f...   \n",
       "24            udnytte avancerede kliniske kompetencer   \n",
       "\n",
       "                                            documents  \n",
       "23  Behandle anmodninger fra havnebrugere og kunde...  \n",
       "24  Anvende avancerede kliniske kompetencer i best...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct = df.iloc[:sample_size,:].loc[(np.array(y_true) == np.array(y_pred))]\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overvåge og vedligeholde boringsvæskerne eller \"mudder\". Tilføje forskellige kemikalier til væsken med henblik på at udføre forskellige funktioner i brøndoperationer: holde borebitten afkølet, hydrostatisk tryk, osv.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect specific document. - Why are 49 and 79 getting this many hits. \n",
    "df.documents[79]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "BERCH embedding Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(q_outputs[0], d_outputs[0], p=0).shape\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62490302a320790e9096d978396a0f6884d50306ab9199b7a47371992da1d123"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('colbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
